{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c47abf6",
   "metadata": {},
   "source": [
    "# Réseau de neurone from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aaf59a",
   "metadata": {},
   "source": [
    "## Définition des classes\n",
    "\n",
    "- Tensor (Trop compliqué car backend numpy en cpp)\n",
    "- Parameter\n",
    "- Function (forward / backward)\n",
    "- Linear\n",
    "- Couche\n",
    "- Adam\n",
    "- Réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9601a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab40253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter:\n",
    "    def __init__(self, data, requires_grad=True):\n",
    "        self._requires_grad = requires_grad\n",
    "        self._grad = None\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256d75b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.modules = {}\n",
    "        self.parameters = []\n",
    "        self.fns = []\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    \n",
    "    def add_module(self, name, module):\n",
    "        if not isinstance(module, Module):\n",
    "            raise TypeError(\"module must be an instance of Module\")\n",
    "        self.modules.update({name: module})\n",
    "        self.parameters.extend(module.get_parameters())\n",
    "\n",
    "    def clear_fns(self):\n",
    "        self.fns = []\n",
    "\n",
    "    def register_parameter(self, parameter):\n",
    "        self.parameters.append(parameter)\n",
    "\n",
    "    def register_function(self, fn):\n",
    "        self.fns.append(fn)\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return self.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8037ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Function:\n",
    "    def __init__(self):\n",
    "        self._input = None\n",
    "        self._output = None\n",
    "        self._grad_input = None\n",
    "        self._grad_output = None\n",
    "\n",
    "    def forward(self, *args):\n",
    "        raise NotImplementedError(\"forward method not implemented\")\n",
    "    def backward(self, *args):\n",
    "        raise NotImplementedError(\"backward method not implemented\")\n",
    "    def __call__(self, *args):\n",
    "        self._input = args\n",
    "        self._output = self.forward(*args)\n",
    "        return self._output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1b2a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Function):\n",
    "    def forward(self, x, y):\n",
    "        assert x.shape[-1] == y.shape[-1], f\"x and y must have the same shape but got {x.shape[-1]} and {y.shape[-1]}\"\n",
    "        return x + y\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output, grad_output.sum(axis=0) / grad_output.shape[0]\n",
    "    \n",
    "class Mult(Function):\n",
    "    def forward(self, x, y):\n",
    "        assert x.shape[-1] == y.shape[-2], f\"impossible to compute matmult due to wrong shape (got {x.shape} and {y.shape})\"\n",
    "        self._input = (x, y)\n",
    "        output = x @ y\n",
    "        return output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        x, y = self._input\n",
    "        # grad_output (batch_size, out_features)\n",
    "        # x (batch_size, in_features)\n",
    "        # y (in_features, out_features)\n",
    "        grad_y = x.T @ grad_output / x.shape[0]\n",
    "        grad_x = grad_output @ y.T\n",
    "        return grad_x, grad_y\n",
    "    \n",
    "class ReLU(Function):\n",
    "    def __init__(self, eps=0):\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        self._input = x\n",
    "        return np.maximum(self.eps * x, x)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        x = self._input\n",
    "        grad_input = np.where(x > 0, grad_output, self.eps * grad_output)\n",
    "        return grad_input\n",
    "    \n",
    "class Identity(Function):\n",
    "    def forward(self, x):\n",
    "        self._input = x\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output    \n",
    "\n",
    "class Arctan(Function):\n",
    "    def forward(self, x):\n",
    "        self._input = x\n",
    "        return np.arctan(x)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        x = self._input\n",
    "        grad_input = grad_output / (1 + x**2)\n",
    "        return grad_input\n",
    "    \n",
    "class Tanh(Function):\n",
    "    def forward(self, x):\n",
    "        self._input = x\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        x = self._input\n",
    "        grad_input = grad_output * (1 - np.tanh(x)**2)\n",
    "        return grad_input\n",
    "    \n",
    "class MSELoss(Function):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        self._input = (y_pred, y_true)\n",
    "        return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    def backward(self, grad_output=1.0):\n",
    "        y_pred, y_true = self._input\n",
    "        grad_input = (2 * (y_pred - y_true))\n",
    "        return grad_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9ba4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(np.random.normal(0, 0.02, size=(in_features, out_features)))\n",
    "        self.register_parameter(self.weight)\n",
    "        if bias:\n",
    "            self.bias = Parameter(np.random.normal(0, 0.02, size=(out_features)))\n",
    "            self.register_parameter(self.bias)\n",
    "        else:\n",
    "            self.bias = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, in_features)\n",
    "        # weight: (in_features, out_features)\n",
    "        # bias: (out_features,)\n",
    "        # output: (batch_size, out_features)\n",
    "        if self.bias is not None:\n",
    "            m = Mult()\n",
    "            self.register_function(m)\n",
    "            a = Add()\n",
    "            self.register_function(a)\n",
    "            res = m(x, self.weight.data)\n",
    "            res = a(res, self.bias.data)\n",
    "            return res\n",
    "        else:\n",
    "            m = Mult()\n",
    "            self.register_function(m)\n",
    "            res = m(x, self.weight.data)\n",
    "            return res\n",
    "        \n",
    "    def backward(self, grad_output):\n",
    "        if self.bias is not None:\n",
    "            dx, db = self.fns[-1].backward(grad_output)\n",
    "            dx, dw = self.fns[-2].backward(dx)\n",
    "            self.weight._grad = dw\n",
    "            self.bias._grad = db\n",
    "            self.clear_fns()\n",
    "            return dx\n",
    "        else:\n",
    "            dx, dw = self.fns[-1].backward(grad_output)\n",
    "            self.weight._grad = dw\n",
    "            self.clear_fns()\n",
    "            return dx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f673d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(Module):\n",
    "    def __init__(self, in_features, out_features, activation=None):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(in_features, out_features)\n",
    "        self.activation = ReLU() if activation is None else activation\n",
    "        self.add_module('linear', self.linear)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear.forward(x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        if self.activation is not None:\n",
    "            grad_output = self.activation.backward(grad_output)\n",
    "        dx = self.linear.backward(grad_output)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f40422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, params, lr=0.001, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.m = [np.zeros_like(p) for p in params]\n",
    "        self.v = [np.zeros_like(p) for p in params]\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "        if len(self.params) == 0:\n",
    "            raise ValueError(\"No parameters to optimize\")\n",
    "        for i, p in enumerate(self.params):\n",
    "            if p._requires_grad:\n",
    "                if (p._grad == .0).all():\n",
    "                    print(\"Gradient is zero\")\n",
    "                grad = p._grad\n",
    "                self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * grad\n",
    "                self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * (grad ** 2)\n",
    "                m_hat = self.m[i] / (1 - self.beta1 ** self.t)\n",
    "                v_hat = self.v[i] / (1 - self.beta2 ** self.t)\n",
    "                update = self.lr * m_hat / (np.sqrt(v_hat) + self.eps)\n",
    "                assert p.data.shape == update.shape, f\"Shape mismatch: {p.data.shape} vs {update.shape}\"\n",
    "                p.data = p.data - update\n",
    "                p._grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0860ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(Module):\n",
    "    def __init__(self, nb_layers=4, in_features=1, out_features=1, hidden_features=16, activation=Arctan()):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        self.loss = MSELoss()\n",
    "        self.register_function(self.loss)\n",
    "        self.layers.append(Layer(in_features, hidden_features, activation))\n",
    "        for _ in range(nb_layers):\n",
    "            layer = Layer(hidden_features, hidden_features, activation)\n",
    "            self.layers.append(layer)\n",
    "        self.layers.append(Linear(hidden_features, out_features))\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            self.add_module(f'layer_{i}', layer)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        if y is not None:\n",
    "            loss = self.loss(x, y)\n",
    "            return x, loss\n",
    "        return x, None\n",
    "\n",
    "    def __call__(self, *args, **kwds):\n",
    "        return super().__call__(*args, **kwds)\n",
    "    \n",
    "    def backward(self):\n",
    "        grad_output = self.loss.backward()\n",
    "        for i, layer in enumerate(reversed(self.layers)):\n",
    "            grad_output = layer.backward(grad_output)\n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54e38cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[2 3]\n",
      " [3 4]\n",
      " [4 5]]\n",
      "Weight 0: [[1 2]\n",
      " [3 4]]\n",
      "Bias 0: [1 2]\n",
      "Weight 1: [[1]\n",
      " [2]]\n",
      "Bias 1: [-1]\n",
      "Output: [[3.51825074]\n",
      " [3.56668501]\n",
      " [3.59578859]]\n",
      "Target: [[3]\n",
      " [4]\n",
      " [5]]\n",
      "Loss: 0.809385127304723\n",
      "dx: [[ 0.01990523  0.04695874]\n",
      " [-0.00937993 -0.02213197]\n",
      " [-0.01947157 -0.0459467 ]]\n",
      "Weight 0 grad: [[-0.00794464 -0.00706362]\n",
      " [-0.00902043 -0.00801677]]\n",
      "Bias 0 grad: [-0.00107579 -0.00095315]\n",
      "Weight 1 grad: [[-1.34546814]\n",
      " [-1.35749428]]\n",
      "Bias 1 grad: [-0.8795171]\n",
      "Updated 0 Weight: [[1.00999999 2.00999999]\n",
      " [3.00999999 4.00999999]]\n",
      "Updated 0 Bias: [1.00999991 2.0099999 ]\n",
      "Updated 1 Weight: [[1.01]\n",
      " [2.01]]\n",
      "Updated 1 Bias: [-0.99]\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(nb_layers=0, in_features=2, out_features=1, hidden_features=2)\n",
    "layer0 = nn.layers[0]\n",
    "layer0.linear.weight.data = np.array([[1,2], [3,4]])\n",
    "layer0.linear.bias.data = np.array([1, 2])\n",
    "linear0 = layer0.linear\n",
    "layer1 = nn.layers[1]\n",
    "layer1.weight.data = np.array([[1], [2]])\n",
    "layer1.bias.data = np.array([-1])\n",
    "x = np.array([[2, 3], [3, 4], [4, 5]])\n",
    "y_hat = np.array([[3], [4], [5]])\n",
    "lin_adam = Adam(nn.get_parameters(), lr=0.01)\n",
    "y, l = nn(x, y_hat)\n",
    "print(f\"Input: {x}\")\n",
    "print(f\"Weight 0: {linear0.weight.data}\")\n",
    "print(f\"Bias 0: {linear0.bias.data}\")\n",
    "print(f\"Weight 1: {layer1.weight.data}\")\n",
    "print(f\"Bias 1: {layer1.bias.data}\")\n",
    "print(f\"Output: {y}\")\n",
    "print(f\"Target: {y_hat}\")\n",
    "dx = nn.backward()\n",
    "print(f\"Loss: {l}\")\n",
    "print(f\"dx: {dx}\")\n",
    "print(f\"Weight 0 grad: {linear0.weight._grad}\")\n",
    "print(f\"Bias 0 grad: {linear0.bias._grad}\")\n",
    "print(f\"Weight 1 grad: {layer1.weight._grad}\")\n",
    "print(f\"Bias 1 grad: {layer1.bias._grad}\")\n",
    "\n",
    "lin_adam.step()\n",
    "print(f\"Updated 0 Weight: {linear0.weight.data}\")\n",
    "print(f\"Updated 0 Bias: {linear0.bias.data}\")\n",
    "print(f\"Updated 1 Weight: {layer1.weight.data}\")\n",
    "print(f\"Updated 1 Bias: {layer1.bias.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79dc2ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7748949895871119\n",
      "Loss: 0.7438655815003553\n",
      "Loss: 0.7163406547748082\n",
      "Loss: 0.6923340838758087\n",
      "Loss: 0.6718220035315948\n",
      "Loss: 0.6547360446443374\n",
      "Loss: 0.6409587578159335\n",
      "Loss: 0.6303183238717571\n",
      "Loss: 0.6225828871996507\n",
      "Loss: 0.6174582557200434\n",
      "Loss: 0.614591417256209\n",
      "Loss: 0.6135809428108129\n",
      "Loss: 0.6139942300135468\n",
      "Loss: 0.6153902433449092\n",
      "Loss: 0.6173451835719268\n",
      "Loss: 0.6194776713291353\n",
      "Loss: 0.6214698551580297\n",
      "Loss: 0.6230815554124013\n",
      "Loss: 0.6241559858902463\n",
      "Loss: 0.6246172545944226\n",
      "Loss: 0.6244611787545358\n",
      "Loss: 0.6237416426345971\n",
      "Loss: 0.6225547840287179\n",
      "Loss: 0.6210229281316179\n",
      "Loss: 0.6192796509634556\n",
      "Loss: 0.61745683884546\n",
      "Loss: 0.6156742092711205\n",
      "Loss: 0.6140314880038323\n",
      "Loss: 0.6126032698412263\n",
      "Loss: 0.6114364839512819\n",
      "Loss: 0.6105503002220135\n",
      "Loss: 0.6099382247966144\n",
      "Loss: 0.609572031597543\n",
      "Loss: 0.6094070691729011\n",
      "Loss: 0.6093883880897217\n",
      "Loss: 0.6094570782570242\n",
      "Loss: 0.6095562094429483\n",
      "Loss: 0.6096358417196264\n",
      "Loss: 0.609656709490859\n",
      "Loss: 0.6095923621118239\n",
      "Loss: 0.6094297361069584\n",
      "Loss: 0.6091683085120699\n",
      "Loss: 0.6088181148504735\n",
      "Loss: 0.6083969966384815\n",
      "Loss: 0.6079274710144024\n",
      "Loss: 0.6074335961338574\n",
      "Loss: 0.606938151685927\n",
      "Loss: 0.6064603765426915\n",
      "Loss: 0.606014416409716\n",
      "Loss: 0.6056085429059307\n",
      "Loss: 0.6052451196465208\n",
      "Loss: 0.6049212172192243\n",
      "Loss: 0.6046297228575611\n",
      "Loss: 0.6043607561312255\n",
      "Loss: 0.6041031911492069\n",
      "Loss: 0.6038460981718563\n",
      "Loss: 0.6035799500115965\n",
      "Loss: 0.6032974856127385\n",
      "Loss: 0.6029941775925522\n",
      "Loss: 0.6026683047221835\n",
      "Loss: 0.6023206775222462\n",
      "Loss: 0.601954100266499\n",
      "Loss: 0.6015726729056811\n",
      "Loss: 0.6011810412450477\n",
      "Loss: 0.6007836946566324\n",
      "Loss: 0.600384390695507\n",
      "Loss: 0.5999857591133004\n",
      "Loss: 0.5995891081090533\n",
      "Loss: 0.5991944271938805\n",
      "Loss: 0.5988005571068539\n",
      "Loss: 0.5984054802034698\n",
      "Loss: 0.598006675923331\n",
      "Loss: 0.5976014854371656\n",
      "Loss: 0.5971874364025699\n",
      "Loss: 0.5967624910975181\n",
      "Loss: 0.5963251967009487\n",
      "Loss: 0.5958747326559389\n",
      "Loss: 0.5954108646084091\n",
      "Loss: 0.5949338256030298\n",
      "Loss: 0.5944441519761257\n",
      "Loss: 0.5939425034062823\n",
      "Loss: 0.5934294942569206\n",
      "Loss: 0.5929055576075576\n",
      "Loss: 0.5923708555005879\n",
      "Loss: 0.5918252403261879\n",
      "Loss: 0.5912682642386583\n",
      "Loss: 0.5906992270935209\n",
      "Loss: 0.5901172492955767\n",
      "Loss: 0.5895213544137249\n",
      "Loss: 0.588910547306119\n",
      "Loss: 0.5882838763352531\n",
      "Loss: 0.5876404723435892\n",
      "Loss: 0.5869795616237091\n",
      "Loss: 0.5863004544082641\n",
      "Loss: 0.585602513824181\n",
      "Loss: 0.5848851124168997\n",
      "Loss: 0.5841475841116223\n",
      "Loss: 0.5833891789283934\n",
      "Loss: 0.5826090261807702\n",
      "Loss: 0.5818061096566362\n",
      "Loss: 0.5809792558386254\n",
      "Loss: 0.5801271339750228\n",
      "Loss: 0.5792482650752432\n",
      "Loss: 0.5783410358683637\n",
      "Loss: 0.5774037134823686\n",
      "Loss: 0.5764344570033368\n",
      "Loss: 0.5754313229883125\n",
      "Loss: 0.5743922632064721\n",
      "Loss: 0.5733151141316358\n",
      "Loss: 0.5721975787933711\n",
      "Loss: 0.5710372023595852\n",
      "Loss: 0.5698313431903368\n",
      "Loss: 0.568577141066298\n",
      "Loss: 0.5672714839178158\n",
      "Loss: 0.5659109737690879\n",
      "Loss: 0.5644918918960388\n",
      "Loss: 0.5630101625017635\n",
      "Loss: 0.5614613136425975\n",
      "Loss: 0.5598404337560711\n",
      "Loss: 0.5581421219723864\n",
      "Loss: 0.5563604304172495\n",
      "Loss: 0.5544887968900455\n",
      "Loss: 0.5525199665663706\n",
      "Loss: 0.5504459016676364\n",
      "Loss: 0.5482576783194218\n",
      "Loss: 0.5459453700718827\n",
      "Loss: 0.5434979178098351\n",
      "Loss: 0.540902986120575\n",
      "Loss: 0.5381468067634722\n",
      "Loss: 0.5352140109305985\n",
      "Loss: 0.5320874538517155\n",
      "Loss: 0.5287480384978965\n",
      "Loss: 0.5251745504487273\n",
      "Loss: 0.5213435245705532\n",
      "Loss: 0.5172291777550911\n",
      "Loss: 0.5128034631808159\n",
      "Loss: 0.5080363340823065\n",
      "Loss: 0.5028963536614447\n",
      "Loss: 0.4973518573851489\n",
      "Loss: 0.4913729644933638\n",
      "Loss: 0.48493482583081554\n",
      "Loss: 0.4780224921167853\n",
      "Loss: 0.47063738074976474\n",
      "Loss: 0.46280361097043293\n",
      "Loss: 0.4545673056565247\n",
      "Loss: 0.4459706233104373\n",
      "Loss: 0.4369750547624777\n",
      "Loss: 0.42736922679017014\n",
      "Loss: 0.41684807409731056\n",
      "Loss: 0.40531126279829094\n",
      "Loss: 0.39301083919980445\n",
      "Loss: 0.3803530462752583\n",
      "Loss: 0.36757238462761466\n",
      "Loss: 0.3545902717801557\n",
      "Loss: 0.34119757609394047\n",
      "Loss: 0.32738466631236524\n",
      "Loss: 0.3134454314273592\n",
      "Loss: 0.29959446378799875\n",
      "Loss: 0.2855691838244852\n",
      "Loss: 0.2710818071819198\n",
      "Loss: 0.2563911081054508\n",
      "Loss: 0.24193532237237217\n",
      "Loss: 0.22768065148049055\n",
      "Loss: 0.21342397291077173\n",
      "Loss: 0.19938511850567708\n",
      "Loss: 0.18582077353182622\n",
      "Loss: 0.17251567687987177\n",
      "Loss: 0.15944113248537545\n",
      "Loss: 0.14695503740956484\n",
      "Loss: 0.13499357624139682\n",
      "Loss: 0.12344781711499202\n",
      "Loss: 0.11258096315611395\n",
      "Loss: 0.10230746593389861\n",
      "Loss: 0.09254924747456678\n",
      "Loss: 0.08353053904067387\n",
      "Loss: 0.07509786420294072\n",
      "Loss: 0.06729079957468309\n",
      "Loss: 0.06017853891021461\n",
      "Loss: 0.05360317854815363\n",
      "Loss: 0.04769746844682335\n",
      "Loss: 0.04234081987882695\n",
      "Loss: 0.03754509813949764\n",
      "Loss: 0.033300026342247706\n",
      "Loss: 0.02951301338282474\n",
      "Loss: 0.02623568381016002\n",
      "Loss: 0.023344625430337756\n",
      "Loss: 0.020886898114421886\n",
      "Loss: 0.018754760349576818\n",
      "Loss: 0.016970265205025006\n",
      "Loss: 0.015456438505834046\n",
      "Loss: 0.014208968768600366\n",
      "Loss: 0.013176367560191667\n",
      "Loss: 0.012339337120867882\n",
      "Loss: 0.011664616591397453\n",
      "Loss: 0.01112694398711035\n",
      "Loss: 0.010703967360307674\n",
      "Loss: 0.010371161420955009\n",
      "Loss: 0.01011297225438955\n",
      "Loss: 0.009909288451530144\n",
      "Loss: 0.009748237572533196\n",
      "Loss: 0.00961572149870348\n",
      "Loss: 0.009502034984057928\n",
      "Loss: 0.009399538811652628\n",
      "Loss: 0.009299317191711098\n",
      "Loss: 0.009199693463347152\n",
      "Loss: 0.009092191997612114\n",
      "Loss: 0.008980083450521861\n",
      "Loss: 0.008854856507422364\n",
      "Loss: 0.008723318827359614\n",
      "Loss: 0.008577596738545966\n",
      "Loss: 0.008426101660992362\n",
      "Loss: 0.008262013449534847\n",
      "Loss: 0.008093608092523592\n",
      "Loss: 0.007916401917341366\n",
      "Loss: 0.007736503613828168\n",
      "Loss: 0.007552304366819969\n",
      "Loss: 0.00736699383862788\n",
      "Loss: 0.007182038551202165\n",
      "Loss: 0.006997412957647962\n",
      "Loss: 0.006816672500472814\n",
      "Loss: 0.006638147468295196\n",
      "Loss: 0.006465533184776333\n",
      "Loss: 0.006297171327140162\n",
      "Loss: 0.0061352479401135815\n",
      "Loss: 0.005979654378553754\n",
      "Loss: 0.00583017719373542\n",
      "Loss: 0.005688123137490173\n",
      "Loss: 0.005552076938764525\n",
      "Loss: 0.005423243773160252\n",
      "Loss: 0.005300591727881026\n",
      "Loss: 0.005184060079289557\n",
      "Loss: 0.0050737820031090545\n",
      "Loss: 0.004968559538845791\n",
      "Loss: 0.004868831325646397\n",
      "Loss: 0.004773720666645462\n",
      "Loss: 0.004682799325427504\n",
      "Loss: 0.004596054232515738\n",
      "Loss: 0.0045125714955631105\n",
      "Loss: 0.004432349309344452\n",
      "Loss: 0.00435495759887867\n",
      "Loss: 0.004279859118317668\n",
      "Loss: 0.004207094644130203\n",
      "Loss: 0.004136152810735008\n",
      "Loss: 0.004066822100067741\n",
      "Loss: 0.003999085078599419\n",
      "Loss: 0.00393254192084914\n",
      "Loss: 0.003867160204474985\n",
      "Loss: 0.0038028968141287562\n",
      "Loss: 0.003739496948297614\n",
      "Loss: 0.0036770068786975293\n",
      "Loss: 0.0036153965665410466\n",
      "Loss: 0.0035545214349062375\n",
      "Loss: 0.003494454332059582\n",
      "Loss: 0.0034351914200824694\n",
      "Loss: 0.0033766538776451045\n",
      "Loss: 0.003318914030104579\n",
      "Loss: 0.0032619898745181244\n",
      "Loss: 0.0032058352527817406\n",
      "Loss: 0.0031505062836571646\n",
      "Loss: 0.0030960325541029843\n",
      "Loss: 0.0030423822069680366\n",
      "Loss: 0.0029895865753787124\n",
      "Loss: 0.0029376764122173923\n",
      "Loss: 0.0028866276366939594\n",
      "Loss: 0.0028364450863851177\n",
      "Loss: 0.002787151448877824\n",
      "Loss: 0.0027387303529444415\n",
      "Loss: 0.0026911657673057607\n",
      "Loss: 0.002644465088951641\n",
      "Loss: 0.002598619697515422\n",
      "Loss: 0.0025536042209976365\n",
      "Loss: 0.0025094082513163122\n",
      "Loss: 0.002466026519659241\n",
      "Loss: 0.00242343638488744\n",
      "Loss: 0.0023816150464391864\n",
      "Loss: 0.002340553033505894\n",
      "Loss: 0.002300235374064915\n",
      "Loss: 0.002260638511488049\n",
      "Loss: 0.0022217454763889736\n",
      "Loss: 0.0021835442575821712\n",
      "Loss: 0.0021460190201437654\n",
      "Loss: 0.0021091510039229554\n",
      "Loss: 0.0020729252880525447\n",
      "Loss: 0.0020373313545340413\n",
      "Loss: 0.0020023558091136133\n",
      "Loss: 0.0019679834135523044\n",
      "Loss: 0.001934202598136617\n",
      "Loss: 0.0019010035866958818\n",
      "Loss: 0.001868376005630225\n",
      "Loss: 0.0018363083708633759\n",
      "Loss: 0.0018047899625580318\n",
      "Loss: 0.001773812546391219\n",
      "Loss: 0.0017433675379859854\n",
      "Loss: 0.0017134454979312187\n",
      "Loss: 0.0016840372616289715\n",
      "Loss: 0.0016551342156375225\n",
      "Loss: 0.0016267288267641704\n",
      "Loss: 0.001598813021808379\n",
      "Loss: 0.0015713782614821946\n",
      "Loss: 0.0015444163398104322\n",
      "Loss: 0.001517919191315317\n",
      "Loss: 0.0014918793691270314\n",
      "Loss: 0.0014662891079336587\n",
      "Loss: 0.001441140456920017\n",
      "Loss: 0.0014164255994198744\n",
      "Loss: 0.0013921367097884984\n",
      "Loss: 0.0013682664570881353\n",
      "Loss: 0.0013448074005174802\n",
      "Loss: 0.0013217522010365301\n",
      "Loss: 0.0012990935264842074\n",
      "Loss: 0.0012768240457676388\n",
      "Loss: 0.0012549367617983112\n",
      "Loss: 0.0012334246820738034\n",
      "Loss: 0.0012122811254646796\n",
      "Loss: 0.0011914994080499393\n",
      "Loss: 0.001171073000966212\n",
      "Loss: 0.0011509954969091145\n",
      "Loss: 0.0011312605641638441\n",
      "Loss: 0.0011118621169083928\n",
      "Loss: 0.0010927941040238486\n",
      "Loss: 0.001074050735235737\n",
      "Loss: 0.0010556262440093228\n",
      "Loss: 0.0010375150741460666\n",
      "Loss: 0.001019711722755015\n",
      "Loss: 0.001002210837011804\n",
      "Loss: 0.0009850071631547913\n",
      "Loss: 0.0009680955450695659\n",
      "Loss: 0.0009514709615069404\n",
      "Loss: 0.0009351284474874794\n",
      "Loss: 0.000919063193306109\n",
      "Loss: 0.0009032704149190976\n",
      "Loss: 0.0008877454956599108\n",
      "Loss: 0.0008724838206454229\n",
      "Loss: 0.0008574809561143637\n",
      "Loss: 0.0008427324469263004\n",
      "Loss: 0.0008282340467653999\n",
      "Loss: 0.0008139814620364964\n",
      "Loss: 0.0007999706740769978\n",
      "Loss: 0.0007861976009721603\n",
      "Loss: 0.0007726586155622411\n",
      "Loss: 0.0007593501170111722\n",
      "Loss: 0.000746269551065199\n",
      "Loss: 0.0007334151181460155\n",
      "Loss: 0.0007207884495713835\n",
      "Loss: 0.0007083962281017901\n",
      "Loss: 0.0006962598869864051\n",
      "Loss: 0.0006844305422252953\n",
      "Loss: 0.000673034503755951\n",
      "Loss: 0.0006623740217959308\n",
      "Loss: 0.0006531738849691447\n",
      "Loss: 0.0006472335247812818\n",
      "Loss: 0.0006487293438500206\n",
      "Loss: 0.00066790893788741\n",
      "Loss: 0.0007231225204051235\n",
      "Loss: 0.0008426475012054797\n",
      "Loss: 0.0009796399170116422\n",
      "Loss: 0.0009822506712300289\n",
      "Loss: 0.0007133609318934494\n",
      "Loss: 0.0005565395771487519\n",
      "Loss: 0.0006978800976875649\n",
      "Loss: 0.0007697406051228897\n",
      "Loss: 0.0005999905099700514\n",
      "Loss: 0.0005304050184292622\n",
      "Loss: 0.0006490193925072144\n",
      "Loss: 0.0006227349379427224\n",
      "Loss: 0.0004967655172437184\n",
      "Loss: 0.0005439744104650721\n",
      "Loss: 0.0005871903772113813\n",
      "Loss: 0.0004899146225202886\n",
      "Loss: 0.0004793703475441842\n",
      "Loss: 0.0005332955911321212\n",
      "Loss: 0.0004781032862102139\n",
      "Loss: 0.0004407104860360861\n",
      "Loss: 0.0004814795297986892\n",
      "Loss: 0.00045884094670917575\n",
      "Loss: 0.0004154235087403947\n",
      "Loss: 0.00043754993015666016\n",
      "Loss: 0.0004349382920656975\n",
      "Loss: 0.00039647932995063857\n",
      "Loss: 0.0004018855442419018\n",
      "Loss: 0.00040890862676948666\n",
      "Loss: 0.0003801584896553849\n",
      "Loss: 0.00037338560702623484\n",
      "Loss: 0.000382483452120434\n",
      "Loss: 0.0003643923217351008\n",
      "Loss: 0.0003506582177761862\n",
      "Loss: 0.0003569473367871969\n",
      "Loss: 0.00034802718356062725\n",
      "Loss: 0.0003322452765439587\n",
      "Loss: 0.0003333466875391538\n",
      "Loss: 0.000330604661923177\n",
      "Loss: 0.000316636397284007\n",
      "Loss: 0.0003124595071176751\n",
      "Loss: 0.000312323185177939\n",
      "Loss: 0.0003023561839198658\n",
      "Loss: 0.000294608299318257\n",
      "Loss: 0.00029394772765945924\n",
      "Loss: 0.00028820132698396397\n",
      "Loss: 0.0002794806566890444\n",
      "Loss: 0.0002765272515423487\n",
      "Loss: 0.0002735546943281187\n",
      "Loss: 0.0002661604160046851\n",
      "Loss: 0.0002609240070270809\n",
      "Loss: 0.0002585740500127777\n",
      "Loss: 0.0002534966386276006\n",
      "Loss: 0.0002473541701919174\n",
      "Loss: 0.00024402639039757166\n",
      "Loss: 0.0002406984224910372\n",
      "Loss: 0.00023526438306164895\n",
      "Loss: 0.00023072847119286495\n",
      "Loss: 0.00022776347930898063\n",
      "Loss: 0.00022373755534380195\n",
      "Loss: 0.00021891829517992555\n",
      "Loss: 0.00021533215758586527\n",
      "Loss: 0.0002122004097188544\n",
      "Loss: 0.00020809850242171465\n",
      "Loss: 0.00020400061486845183\n",
      "Loss: 0.00020082111073825644\n",
      "Loss: 0.00019757274446226185\n",
      "Loss: 0.0001937215752927857\n",
      "Loss: 0.0001901601051219956\n",
      "Loss: 0.0001871555421592043\n",
      "Loss: 0.0001839478784047066\n",
      "Loss: 0.0001804321483724453\n",
      "Loss: 0.00017722779244449378\n",
      "Loss: 0.00017434575234960876\n",
      "Loss: 0.00017128684080917986\n",
      "Loss: 0.00016808264647800327\n",
      "Loss: 0.00016512885738238314\n",
      "Loss: 0.0001623764225391533\n",
      "Loss: 0.00015950920932353746\n",
      "Loss: 0.00015657245252900112\n",
      "Loss: 0.00015381668218341935\n",
      "Loss: 0.00015120600073903535\n",
      "Loss: 0.0001485379358373432\n",
      "Loss: 0.00014583198618101903\n",
      "Loss: 0.00014324937755681347\n",
      "Loss: 0.000140784330494855\n",
      "Loss: 0.00013830642474472476\n",
      "Loss: 0.00013580579520584344\n",
      "Loss: 0.00013338408980474432\n",
      "Loss: 0.00013106133928326156\n",
      "Loss: 0.00012875834002821826\n",
      "Loss: 0.00012644505662591033\n",
      "Loss: 0.0001241779411067283\n",
      "Loss: 0.00012199095462862406\n",
      "Loss: 0.00011984530040354659\n",
      "Loss: 0.00011770407255434522\n",
      "Loss: 0.00011558821025976444\n",
      "Loss: 0.00011353143704894428\n",
      "Loss: 0.00011152554743996376\n",
      "Loss: 0.00010954046441066815\n",
      "Loss: 0.00010757248466898269\n",
      "Loss: 0.0001056435032348727\n",
      "Loss: 0.0001037630237769378\n",
      "Loss: 0.00010191629851277624\n",
      "Loss: 0.00010008953405750935\n",
      "Loss: 9.828821339416735e-05\n",
      "Loss: 9.652481810280459e-05\n",
      "Loss: 9.479952083995046e-05\n",
      "Loss: 9.310183468730507e-05\n",
      "Loss: 9.14262062217563e-05\n",
      "Loss: 8.97775928076294e-05\n",
      "Loss: 8.816222139190179e-05\n",
      "Loss: 8.657867356576005e-05\n",
      "Loss: 8.502069852225006e-05\n",
      "Loss: 8.348550125225195e-05\n",
      "Loss: 8.197585190284056e-05\n",
      "Loss: 8.049503159616052e-05\n",
      "Loss: 7.904223396960117e-05\n",
      "Loss: 7.761387894128204e-05\n",
      "Loss: 7.620790121242004e-05\n",
      "Loss: 7.482528226003832e-05\n",
      "Loss: 7.346785404214181e-05\n",
      "Loss: 7.213560174255318e-05\n",
      "Loss: 7.082664743945139e-05\n",
      "Loss: 6.953926772012295e-05\n",
      "Loss: 6.827325749070621e-05\n",
      "Loss: 6.702944431183556e-05\n",
      "Loss: 6.580820885497812e-05\n",
      "Loss: 6.460883912280721e-05\n",
      "Loss: 6.343012046724887e-05\n",
      "Loss: 6.22712715902541e-05\n",
      "Loss: 6.113228112548816e-05\n",
      "Loss: 6.0013406336618815e-05\n",
      "Loss: 5.891457917297474e-05\n",
      "Loss: 5.783523393195668e-05\n",
      "Loss: 5.677462828866615e-05\n",
      "Loss: 5.5732258427298096e-05\n",
      "Loss: 5.4707951696183045e-05\n",
      "Loss: 5.370169005243662e-05\n",
      "Loss: 5.271332950601364e-05\n",
      "Loss: 5.1742509461976715e-05\n",
      "Loss: 5.0788753311665145e-05\n",
      "Loss: 4.9851631612716746e-05\n",
      "Loss: 4.893086657112893e-05\n",
      "Loss: 4.802628429645167e-05\n",
      "Loss: 4.713772634091603e-05\n",
      "Loss: 4.626496116462307e-05\n",
      "Loss: 4.540767988133515e-05\n",
      "Loss: 4.456554547821689e-05\n",
      "Loss: 4.373824550702217e-05\n",
      "Loss: 4.29255278633422e-05\n",
      "Loss: 4.21271804810102e-05\n",
      "Loss: 4.1343007687982324e-05\n",
      "Loss: 4.057279498083409e-05\n",
      "Loss: 3.981630355683375e-05\n",
      "Loss: 3.9073278183576635e-05\n",
      "Loss: 3.834346282792115e-05\n",
      "Loss: 3.762661842675052e-05\n",
      "Loss: 3.692252241853384e-05\n",
      "Loss: 3.623097036547685e-05\n",
      "Loss: 3.5551762287249e-05\n",
      "Loss: 3.4884699908034965e-05\n",
      "Loss: 3.422957976972418e-05\n",
      "Loss: 3.358619554698917e-05\n",
      "Loss: 3.295434064188097e-05\n",
      "Loss: 3.233381065914708e-05\n",
      "Loss: 3.172440786993601e-05\n",
      "Loss: 3.112593931154489e-05\n",
      "Loss: 3.0538219535154844e-05\n",
      "Loss: 2.996106611346141e-05\n",
      "Loss: 2.9394301550983182e-05\n",
      "Loss: 2.8837749491059962e-05\n",
      "Loss: 2.8291236597505348e-05\n",
      "Loss: 2.7754590662771168e-05\n",
      "Loss: 2.7227642033827855e-05\n",
      "Loss: 2.6710223211686324e-05\n",
      "Loss: 2.620216926729826e-05\n",
      "Loss: 2.5703318307607747e-05\n",
      "Loss: 2.52135108581313e-05\n",
      "Loss: 2.473259086197348e-05\n",
      "Loss: 2.4260404353392408e-05\n",
      "Loss: 2.3796800845894564e-05\n",
      "Loss: 2.334163162418604e-05\n",
      "Loss: 2.2894751433226398e-05\n",
      "Loss: 2.2456016573688975e-05\n",
      "Loss: 2.2025286846189667e-05\n",
      "Loss: 2.1602423507602134e-05\n",
      "Loss: 2.1187291509952762e-05\n",
      "Loss: 2.0779757311358533e-05\n",
      "Loss: 2.0379691595880532e-05\n",
      "Loss: 1.998696695724586e-05\n",
      "Loss: 1.9601461568548198e-05\n",
      "Loss: 1.9223056983852592e-05\n",
      "Loss: 1.8851643916983722e-05\n",
      "Loss: 1.848712128329732e-05\n",
      "Loss: 1.8129407241399882e-05\n",
      "Loss: 1.7778443721823612e-05\n",
      "Loss: 1.743422223308515e-05\n",
      "Loss: 1.709680928403487e-05\n",
      "Loss: 1.6766418049788222e-05\n",
      "Loss: 1.6443511016090664e-05\n",
      "Loss: 1.6129026131646608e-05\n",
      "Loss: 1.58247686024507e-05\n",
      "Loss: 1.5534191634051595e-05\n",
      "Loss: 1.5263906048523513e-05\n",
      "Loss: 1.502655494525788e-05\n",
      "Loss: 1.4846824908576415e-05\n",
      "Loss: 1.4772534069381942e-05\n",
      "Loss: 1.4899584783184166e-05\n",
      "Loss: 1.541586245981121e-05\n",
      "Loss: 1.6708948593390334e-05\n",
      "Loss: 1.953626176787666e-05\n",
      "Loss: 2.54942487603469e-05\n",
      "Loss: 3.755022083570981e-05\n",
      "Loss: 6.182698252475216e-05\n",
      "Loss: 0.00010710763016420068\n",
      "Loss: 0.00018694151622322585\n",
      "Loss: 0.00029213100159054725\n",
      "Loss: 0.00038100854372368365\n",
      "Loss: 0.00032818361954198495\n",
      "Loss: 0.00014886437894997398\n",
      "Loss: 1.5161812960206933e-05\n",
      "Loss: 6.58714994048238e-05\n",
      "Loss: 0.00018378936229789629\n",
      "Loss: 0.00017273624906412834\n",
      "Loss: 5.542925488154937e-05\n",
      "Loss: 1.3567613666551452e-05\n",
      "Loss: 8.701240364044267e-05\n",
      "Loss: 0.00012425233257846535\n",
      "Loss: 5.6516656565693393e-05\n",
      "Loss: 9.207277238819772e-06\n",
      "Loss: 5.0290435025413114e-05\n",
      "Loss: 8.254116849658334e-05\n",
      "Loss: 4.3691044811481354e-05\n",
      "Loss: 8.547424628147475e-06\n",
      "Loss: 3.374126950748864e-05\n",
      "Loss: 5.718213955016105e-05\n",
      "Loss: 3.115119262635265e-05\n",
      "Loss: 7.885580998707352e-06\n",
      "Loss: 2.4861491196745443e-05\n",
      "Loss: 3.956070889574566e-05\n",
      "Loss: 2.2281438904841076e-05\n",
      "Loss: 7.276574424649577e-06\n",
      "Loss: 1.8834893972693608e-05\n",
      "Loss: 2.838278432933554e-05\n",
      "Loss: 1.642214765145519e-05\n",
      "Loss: 6.72423730094132e-06\n",
      "Loss: 1.448606896429975e-05\n",
      "Loss: 2.0554698575682493e-05\n",
      "Loss: 1.2738165115609234e-05\n",
      "Loss: 6.2112584284581115e-06\n",
      "Loss: 1.115914461624951e-05\n",
      "Loss: 1.5387685762867072e-05\n",
      "Loss: 1.035248940562e-05\n",
      "Loss: 5.747362398320717e-06\n",
      "Loss: 8.685977697216658e-06\n",
      "Loss: 1.1716253033527642e-05\n",
      "Loss: 8.752183095317e-06\n",
      "Loss: 5.357537475764297e-06\n",
      "Loss: 6.8586964517626244e-06\n",
      "Loss: 9.14265723232292e-06\n",
      "Loss: 7.5704891910247444e-06\n",
      "Loss: 5.047097735140379e-06\n",
      "Loss: 5.556883026891352e-06\n",
      "Loss: 7.224242558030977e-06\n",
      "Loss: 6.625732277847912e-06\n",
      "Loss: 4.80330811142626e-06\n",
      "Loss: 4.666506345321469e-06\n",
      "Loss: 5.794136238995857e-06\n",
      "Loss: 5.786442561867207e-06\n",
      "Loss: 4.585384941893601e-06\n",
      "Loss: 4.092619770471998e-06\n",
      "Loss: 4.7174189463696586e-06\n",
      "Loss: 5.01296949013316e-06\n",
      "Loss: 4.346853575147093e-06\n",
      "Loss: 3.745140009010162e-06\n",
      "Loss: 3.941949053192539e-06\n",
      "Loss: 4.292087430305559e-06\n",
      "Loss: 4.047908104579587e-06\n",
      "Loss: 3.5289250624103183e-06\n",
      "Loss: 3.4216888063116654e-06\n",
      "Loss: 3.659877563663383e-06\n",
      "Loss: 3.6750079313961192e-06\n",
      "Loss: 3.3499482870217216e-06\n",
      "Loss: 3.100813177532025e-06\n",
      "Loss: 3.156018780323364e-06\n",
      "Loss: 3.2580099459194428e-06\n",
      "Loss: 3.1354017284712756e-06\n",
      "Loss: 2.8983974669912047e-06\n",
      "Loss: 2.802898053950713e-06\n",
      "Loss: 2.857246214978013e-06\n",
      "Loss: 2.8600650370304755e-06\n",
      "Loss: 2.7243239553691807e-06\n",
      "Loss: 2.5754625635380764e-06\n",
      "Loss: 2.5349213096805336e-06\n",
      "Loss: 2.5548912913032684e-06\n",
      "Loss: 2.517350755667847e-06\n",
      "Loss: 2.4068453071983494e-06\n",
      "Loss: 2.310398150473552e-06\n",
      "Loss: 2.2812753248699472e-06\n",
      "Loss: 2.275955255285818e-06\n",
      "Loss: 2.230376265955314e-06\n",
      "Loss: 2.1465675061307603e-06\n",
      "Loss: 2.076611130329851e-06\n",
      "Loss: 2.046307698967946e-06\n",
      "Loss: 2.028131322772005e-06\n",
      "Loss: 1.986337360922869e-06\n",
      "Loss: 1.9226146465167502e-06\n",
      "Loss: 1.8663523864558618e-06\n",
      "Loss: 1.833324349484993e-06\n",
      "Loss: 1.8095619049759176e-06\n",
      "Loss: 1.7740136070326806e-06\n",
      "Loss: 1.7246903478345066e-06\n",
      "Loss: 1.6770405388175762e-06\n",
      "Loss: 1.6425063525313896e-06\n",
      "Loss: 1.6162831047301862e-06\n",
      "Loss: 1.586076810010246e-06\n",
      "Loss: 1.547357998740406e-06\n",
      "Loss: 1.5067444622139256e-06\n",
      "Loss: 1.4724169805233593e-06\n",
      "Loss: 1.4449262993775788e-06\n",
      "Loss: 1.4181710238465345e-06\n",
      "Loss: 1.3872227099162007e-06\n",
      "Loss: 1.3532253939685518e-06\n",
      "Loss: 1.3209208367449681e-06\n",
      "Loss: 1.2930303177859726e-06\n",
      "Loss: 1.2679096477082192e-06\n",
      "Loss: 1.2420946236912935e-06\n",
      "Loss: 1.2140916968407432e-06\n",
      "Loss: 1.1854050897780447e-06\n",
      "Loss: 1.1584430723819502e-06\n",
      "Loss: 1.134021762339315e-06\n",
      "Loss: 1.1109239273538481e-06\n",
      "Loss: 1.0874484615096232e-06\n",
      "Loss: 1.0630600268746745e-06\n",
      "Loss: 1.0386146948531888e-06\n",
      "Loss: 1.0152895886126034e-06\n",
      "Loss: 9.934696067176694e-07\n",
      "Loss: 9.725740959046455e-07\n",
      "Loss: 9.517520488044844e-07\n",
      "Loss: 9.306493906008469e-07\n",
      "Loss: 9.095880819776072e-07\n",
      "Loss: 8.89148699494002e-07\n",
      "Loss: 8.696387253483819e-07\n",
      "Loss: 8.509003460346266e-07\n",
      "Loss: 8.325282405913137e-07\n",
      "Loss: 8.142291288883365e-07\n",
      "Loss: 7.960130220782266e-07\n",
      "Loss: 7.781132840771272e-07\n",
      "Loss: 7.607604739142807e-07\n",
      "Loss: 7.440112434060897e-07\n",
      "Loss: 7.277411893956531e-07\n",
      "Loss: 7.11766357383174e-07\n",
      "Loss: 6.959773460309239e-07\n",
      "Loss: 6.803911838431701e-07\n",
      "Loss: 6.651073067303692e-07\n",
      "Loss: 6.502202091275737e-07\n",
      "Loss: 6.357564702370309e-07\n",
      "Loss: 6.216694686934682e-07\n",
      "Loss: 6.078804752878145e-07\n",
      "Loss: 5.943292514945711e-07\n",
      "Loss: 5.810013145571511e-07\n",
      "Loss: 5.679223365912771e-07\n",
      "Loss: 5.551311069867958e-07\n",
      "Loss: 5.426521854801728e-07\n",
      "Loss: 5.304830084182155e-07\n",
      "Loss: 5.185986958873328e-07\n",
      "Loss: 5.069672149005079e-07\n",
      "Loss: 4.955642901709348e-07\n",
      "Loss: 4.843808367884367e-07\n",
      "Loss: 4.734211231753298e-07\n",
      "Loss: 4.626953492788028e-07\n",
      "Loss: 4.5221139591233323e-07\n",
      "Loss: 4.419699159857452e-07\n",
      "Loss: 4.3196381965947597e-07\n",
      "Loss: 4.2218120593928597e-07\n",
      "Loss: 4.126095019283461e-07\n",
      "Loss: 4.03238733548443e-07\n",
      "Loss: 3.9406299461150975e-07\n",
      "Loss: 3.850799567600328e-07\n",
      "Loss: 3.7628934088600983e-07\n",
      "Loss: 3.6769106654065333e-07\n",
      "Loss: 3.592839601865009e-07\n",
      "Loss: 3.5106516886995813e-07\n",
      "Loss: 3.430303326357703e-07\n",
      "Loss: 3.351741655762196e-07\n",
      "Loss: 3.274911527971373e-07\n",
      "Loss: 3.199761312206038e-07\n",
      "Loss: 3.126245876954316e-07\n",
      "Loss: 3.0543274588263174e-07\n",
      "Loss: 2.98397419405157e-07\n",
      "Loss: 2.915158288360945e-07\n",
      "Loss: 2.8478536044465826e-07\n",
      "Loss: 2.782034228729775e-07\n",
      "Loss: 2.7176732741434416e-07\n",
      "Loss: 2.6547427301073714e-07\n",
      "Loss: 2.593213461560803e-07\n",
      "Loss: 2.53305572589894e-07\n",
      "Loss: 2.474239581252047e-07\n",
      "Loss: 2.4167353624969116e-07\n",
      "Loss: 2.3605139897042155e-07\n",
      "Loss: 2.3055471503184072e-07\n",
      "Loss: 2.2518074213856863e-07\n",
      "Loss: 2.1992682262172522e-07\n",
      "Loss: 2.1479038709974663e-07\n",
      "Loss: 2.0976894155420897e-07\n",
      "Loss: 2.048600725595594e-07\n",
      "Loss: 2.000614352601744e-07\n",
      "Loss: 1.9537076588275013e-07\n",
      "Loss: 1.907858759352647e-07\n",
      "Loss: 1.8630467672219452e-07\n",
      "Loss: 1.8192518627625196e-07\n",
      "Loss: 1.7764557622129217e-07\n",
      "Loss: 1.7346420772025293e-07\n",
      "Loss: 1.693797284586984e-07\n",
      "Loss: 1.653911819024878e-07\n",
      "Loss: 1.6149822851688927e-07\n",
      "Loss: 1.577014494635188e-07\n",
      "Loss: 1.5400289369566727e-07\n",
      "Loss: 1.504069153641702e-07\n",
      "Loss: 1.4692161450719388e-07\n",
      "Loss: 1.4356119018020565e-07\n",
      "Loss: 1.4034993329955596e-07\n",
      "Loss: 1.3732904055651786e-07\n",
      "Loss: 1.3456818441439864e-07\n",
      "Loss: 1.321859473898619e-07\n",
      "Loss: 1.303847396878441e-07\n",
      "Loss: 1.295144153356596e-07\n",
      "Loss: 1.301817369364499e-07\n",
      "Loss: 1.334562362910953e-07\n",
      "Loss: 1.4122584953186168e-07\n",
      "Loss: 1.5688999252172478e-07\n",
      "Loss: 1.8655352739251e-07\n",
      "Loss: 2.414567462791187e-07\n",
      "Loss: 3.4209860533480374e-07\n",
      "Loss: 5.271172549670714e-07\n",
      "Loss: 8.678026331757637e-07\n",
      "Loss: 1.5019110037461369e-06\n",
      "Loss: 2.6845630943919885e-06\n",
      "Loss: 4.9214212992291625e-06\n",
      "Loss: 9.134397827272568e-06\n",
      "Loss: 1.718569041878758e-05\n",
      "Loss: 3.2228230103251507e-05\n",
      "Loss: 6.049258029201768e-05\n",
      "Loss: 0.00010961630060289581\n",
      "Loss: 0.00019113656905198477\n",
      "Loss: 0.0002935651354519864\n",
      "Loss: 0.00038320633347037157\n",
      "Loss: 0.0003505537730597139\n",
      "Loss: 0.00019195716250215993\n",
      "Loss: 2.7315917411336286e-05\n",
      "Loss: 1.8004715692829476e-05\n",
      "Loss: 0.00012896202821909358\n",
      "Loss: 0.00018875174711934723\n",
      "Loss: 0.00011762157184775744\n",
      "Loss: 1.413588302184208e-05\n",
      "Loss: 1.7776786054665928e-05\n",
      "Loss: 9.229521378110787e-05\n",
      "Loss: 0.00010505604187330236\n",
      "Loss: 3.997992692834844e-05\n",
      "Loss: 9.103042708740556e-08\n",
      "Loss: 3.4975999604137734e-05\n",
      "Loss: 7.026946492134799e-05\n",
      "Loss: 4.364471744461572e-05\n",
      "Loss: 3.5691186512336547e-06\n",
      "Loss: 1.0868393017412871e-05\n",
      "Loss: 4.036197325298758e-05\n",
      "Loss: 3.688799543868606e-05\n",
      "Loss: 8.08978585170792e-06\n",
      "Loss: 2.1943508359797725e-06\n",
      "Loss: 2.137116448598239e-05\n",
      "Loss: 2.7035853706905195e-05\n",
      "Loss: 1.0278107326428344e-05\n",
      "Loss: 8.395059586952676e-08\n",
      "Loss: 9.814120461860423e-06\n",
      "Loss: 1.8305220017342712e-05\n",
      "Loss: 1.0407219094276208e-05\n",
      "Loss: 5.605508899929076e-07\n",
      "Loss: 3.6047401098995643e-06\n",
      "Loss: 1.1058099980421188e-05\n",
      "Loss: 9.197134780731083e-06\n",
      "Loss: 1.7527698025812638e-06\n",
      "Loss: 7.918643546946891e-07\n",
      "Loss: 5.84822852590306e-06\n",
      "Loss: 7.116351294537362e-06\n",
      "Loss: 2.731425529699398e-06\n",
      "Loss: 4.397075761030919e-08\n",
      "Loss: 2.4332319020892537e-06\n",
      "Loss: 4.801173990301436e-06\n",
      "Loss: 3.084967934573745e-06\n",
      "Loss: 3.447425352541092e-07\n",
      "Loss: 6.329495792730849e-07\n",
      "Loss: 2.64791393277395e-06\n",
      "Loss: 2.7589788357464395e-06\n",
      "Loss: 9.175619172617727e-07\n",
      "Loss: 4.783446446689168e-08\n",
      "Loss: 1.0716323423913305e-06\n",
      "Loss: 1.9404232237184565e-06\n",
      "Loss: 1.2529360889091805e-06\n",
      "Loss: 1.7153685179967867e-07\n",
      "Loss: 2.2722240196645342e-07\n",
      "Loss: 1.0132258626155559e-06\n",
      "Loss: 1.1565606654541714e-06\n",
      "Loss: 4.85576752213863e-07\n",
      "Loss: 2.9106710182958115e-08\n",
      "Loss: 3.2179267812035883e-07\n",
      "Loss: 7.448478189718587e-07\n",
      "Loss: 6.219850651091023e-07\n",
      "Loss: 1.7595607446544955e-07\n",
      "Loss: 3.702955333411058e-08\n",
      "Loss: 2.9564303627246956e-07\n",
      "Loss: 4.854147884139657e-07\n",
      "Loss: 3.2714661345448724e-07\n",
      "Loss: 6.976330970677979e-08\n",
      "Loss: 4.879196955543347e-08\n",
      "Loss: 2.2235143946983497e-07\n",
      "Loss: 3.018627716140896e-07\n",
      "Loss: 1.8036412211679124e-07\n",
      "Loss: 3.6442922041559174e-08\n",
      "Loss: 4.4263728928105784e-08\n",
      "Loss: 1.5023141731521812e-07\n",
      "Loss: 1.8721341677683999e-07\n",
      "Loss: 1.0936620581341121e-07\n",
      "Loss: 2.5846514686654274e-08\n",
      "Loss: 3.238909544024484e-08\n",
      "Loss: 9.502890061741096e-08\n",
      "Loss: 1.1811678405127427e-07\n",
      "Loss: 7.379119658287676e-08\n",
      "Loss: 2.2298031036323925e-08\n",
      "Loss: 2.121350620820013e-08\n",
      "Loss: 5.703298342029309e-08\n",
      "Loss: 7.556496605660197e-08\n",
      "Loss: 5.401196523448419e-08\n",
      "Loss: 2.133925047526359e-08\n",
      "Loss: 1.4013149487531532e-08\n",
      "Loss: 3.248106988174322e-08\n",
      "Loss: 4.79435992113532e-08\n",
      "Loss: 4.090494939206876e-08\n",
      "Loss: 2.121222007741611e-08\n",
      "Loss: 1.1036332994678468e-08\n",
      "Loss: 1.7856057461165218e-08\n",
      "Loss: 2.9232699137862184e-08\n",
      "Loss: 3.037902732340803e-08\n",
      "Loss: 2.057347214567195e-08\n",
      "Loss: 1.1020700549930788e-08\n",
      "Loss: 1.0552085423683842e-08\n",
      "Loss: 1.6829930053941943e-08\n",
      "Loss: 2.106300430453092e-08\n",
      "Loss: 1.8385906618219715e-08\n",
      "Loss: 1.2002409895928684e-08\n",
      "Loss: 8.286623762943329e-09\n",
      "Loss: 9.734404131998396e-09\n",
      "Loss: 1.3284985312071462e-08\n",
      "Loss: 1.4471964555348118e-08\n",
      "Loss: 1.205232377297455e-08\n",
      "Loss: 8.536398043077573e-09\n",
      "Loss: 7.0095739537870275e-09\n",
      "Loss: 8.099817923900737e-09\n",
      "Loss: 9.89842198403634e-09\n",
      "Loss: 1.024964092698393e-08\n",
      "Loss: 8.773378832368946e-09\n",
      "Loss: 6.83543861473046e-09\n",
      "Loss: 5.959762526137628e-09\n",
      "Loss: 6.443417380864045e-09\n",
      "Loss: 7.352194655715935e-09\n",
      "Loss: 7.586791828568858e-09\n",
      "Loss: 6.857186465797393e-09\n",
      "Loss: 5.757606821921501e-09\n",
      "Loss: 5.081700922272449e-09\n",
      "Loss: 5.123929173878169e-09\n",
      "Loss: 5.543629285436668e-09\n",
      "Loss: 5.7736213754033785e-09\n",
      "Loss: 5.519846535496664e-09\n",
      "Loss: 4.9340821010587385e-09\n",
      "Loss: 4.400970835873188e-09\n",
      "Loss: 4.192685745778171e-09\n",
      "Loss: 4.286527069946867e-09\n",
      "Loss: 4.444556796518469e-09\n",
      "Loss: 4.434780501173343e-09\n",
      "Loss: 4.198379121009772e-09\n",
      "Loss: 3.854298262902127e-09\n",
      "Loss: 3.5766923666379277e-09\n",
      "Loss: 3.4613219644708163e-09\n",
      "Loss: 3.476557891398237e-09\n",
      "Loss: 3.5122399515897678e-09\n",
      "Loss: 3.4700351686238547e-09\n",
      "Loss: 3.3253215260078393e-09\n",
      "Loss: 3.126841963857915e-09\n",
      "Loss: 2.949536414210645e-09\n",
      "Loss: 2.8417236422920034e-09\n",
      "Loss: 2.8010999097474547e-09\n",
      "Loss: 2.7872113149593314e-09\n",
      "Loss: 2.7539096178979327e-09\n",
      "Loss: 2.6775678056911507e-09\n",
      "Loss: 2.565578446247839e-09\n",
      "Loss: 2.4451997442143333e-09\n",
      "Loss: 2.3439118966285283e-09\n",
      "Loss: 2.274353184734485e-09\n",
      "Loss: 2.230860770747622e-09\n",
      "Loss: 2.1965334847157536e-09\n",
      "Loss: 2.1544260044118178e-09\n",
      "Loss: 2.09604960358247e-09\n",
      "Loss: 2.023591135361943e-09\n",
      "Loss: 1.9463659035187226e-09\n",
      "Loss: 1.8747424193846232e-09\n",
      "Loss: 1.8150733552705834e-09\n",
      "Loss: 1.767732991213357e-09\n",
      "Loss: 1.7283253387622188e-09\n",
      "Loss: 1.6906791216497787e-09\n",
      "Loss: 1.6498452128884e-09\n",
      "Loss: 1.6038190618583809e-09\n",
      "Loss: 1.5536227422098687e-09\n",
      "Loss: 1.5021602197145107e-09\n",
      "Loss: 1.4526436860339808e-09\n",
      "Loss: 1.407315122194758e-09\n",
      "Loss: 1.366864239273717e-09\n",
      "Loss: 1.3305574755398733e-09\n",
      "Loss: 1.296828514006599e-09\n",
      "Loss: 1.26399101336572e-09\n",
      "Loss: 1.2307961958346238e-09\n",
      "Loss: 1.196697460521717e-09\n",
      "Loss: 1.1618239208114368e-09\n",
      "Loss: 1.1267595965982024e-09\n",
      "Loss: 1.0922531408674717e-09\n",
      "Loss: 1.0589656323074423e-09\n",
      "Loss: 1.0273156793602884e-09\n",
      "Loss: 9.974343638537043e-10\n",
      "Loss: 9.692068707655773e-10\n",
      "Loss: 9.423620199396563e-10\n",
      "Loss: 9.165715082572738e-10\n",
      "Loss: 8.915314674572847e-10\n",
      "Loss: 8.670130005903087e-10\n",
      "Loss: 8.428807278752468e-10\n",
      "Loss: 8.190862934139623e-10\n",
      "Loss: 7.956469092330166e-10\n",
      "Loss: 7.726188139801931e-10\n",
      "Loss: 7.500726497423318e-10\n",
      "Loss: 7.280749993955248e-10\n",
      "Loss: 7.066771422491098e-10\n",
      "Loss: 6.859104753104016e-10\n",
      "Loss: 6.657868067643404e-10\n",
      "Loss: 6.463016231716923e-10\n",
      "Loss: 6.274386240033802e-10\n",
      "Loss: 6.091742749560493e-10\n",
      "Loss: 5.914816906506155e-10\n",
      "Loss: 5.743335056553965e-10\n",
      "Loss: 5.577037610272554e-10\n",
      "Loss: 5.415689382308578e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[2.99998549],\n",
       "        [4.00002992],\n",
       "        [4.99997827]]),\n",
       " None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    y, l = nn(x, y_hat)\n",
    "    dx = nn.backward()\n",
    "    print(f\"Loss: {l}\")\n",
    "    lin_adam.step()\n",
    "nn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f263d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, min_max_value, nb_data=1000, eval_ratio=0.1, batch_size=32):\n",
    "        self.min_max_value = min_max_value\n",
    "        self.nb_data = nb_data\n",
    "        self.eval_ratio = eval_ratio\n",
    "        self.batch_size = batch_size\n",
    "        x_ = np.random.uniform(-min_max_value, min_max_value, size=(nb_data, batch_size, 1))\n",
    "        y_ = np.sin(x_)\n",
    "        self.nb_eval = int(nb_data * eval_ratio)\n",
    "        self.x_train = x_[:-self.nb_eval, :, :]\n",
    "        self.y_train = y_[:-self.nb_eval, :, :]\n",
    "        self.x_eval = x_[-self.nb_eval:, :, :]\n",
    "        self.y_eval = y_[-self.nb_eval:, :, :]\n",
    "\n",
    "    def get_train_data(self):\n",
    "        return self.x_train, self.y_train\n",
    "    \n",
    "    def get_eval_data(self):\n",
    "        return self.x_eval, self.y_eval\n",
    "    \n",
    "    def eval_len(self):\n",
    "        return self.x_eval.shape[0]\n",
    "    \n",
    "    def train_len(self):\n",
    "        return self.x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_Scheduler:\n",
    "    def __init__(self, optimizer, start_value=0.1, end_value=0.01, nb_steps=1000):\n",
    "        self.optimizer = optimizer\n",
    "        self.start_value = start_value\n",
    "        self.end_value = end_value\n",
    "        self.nb_steps = nb_steps\n",
    "        self.current_step = 0\n",
    "\n",
    "    def step(self):\n",
    "        if self.current_step < self.nb_steps:\n",
    "            lr = self.start_value * np.exp(-5 * self.current_step / self.nb_steps)\n",
    "            self.optimizer.lr = lr\n",
    "            self.current_step += 1\n",
    "        else:\n",
    "            self.optimizer.lr = self.end_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aeed3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(nb_layers=2, in_features=1, out_features=1, hidden_features=128, activation=Tanh())\n",
    "adam = Adam(model.get_parameters(), lr=0.02)\n",
    "nb_data = int(5*1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c47ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_value = 10 \n",
    "batch_size = 64\n",
    "nb_epochs = 10\n",
    "\n",
    "dataset = Dataset(min_max_value, nb_data=nb_data, eval_ratio=0.1, batch_size=batch_size)\n",
    "\n",
    "scheduler = LR_Scheduler(adam, start_value=0.02, end_value=1e-7, nb_steps=dataset.train_len() * nb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd1b9762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.610e-04 with the lr=2.000e-02 at step 0 in epoch 0\n",
      "1.245e-04 with the lr=1.750e-02 at step 2000 in epoch 0\n",
      "3.223e-05 with the lr=1.532e-02 at step 4000 in epoch 0\n",
      "Evaluation: 0.05306154775536759\n",
      "2.507e-05 with the lr=1.482e-02 at step 0 in epoch 1\n",
      "1.002e-05 with the lr=1.297e-02 at step 2000 in epoch 1\n",
      "5.210e-06 with the lr=1.135e-02 at step 4000 in epoch 1\n",
      "Evaluation: 0.01627924094042509\n",
      "8.256e-06 with the lr=1.098e-02 at step 0 in epoch 2\n",
      "3.254e-06 with the lr=9.606e-03 at step 2000 in epoch 2\n",
      "4.198e-06 with the lr=8.407e-03 at step 4000 in epoch 2\n",
      "Evaluation: 0.0059982001897673455\n",
      "3.237e-06 with the lr=8.131e-03 at step 0 in epoch 3\n",
      "2.764e-06 with the lr=7.116e-03 at step 2000 in epoch 3\n",
      "9.176e-07 with the lr=6.228e-03 at step 4000 in epoch 3\n",
      "Evaluation: 0.002229782200587432\n",
      "6.331e-07 with the lr=6.024e-03 at step 0 in epoch 4\n",
      "4.399e-06 with the lr=5.272e-03 at step 2000 in epoch 4\n",
      "2.055e-06 with the lr=4.614e-03 at step 4000 in epoch 4\n",
      "Evaluation: 0.0015672805335623648\n",
      "7.733e-07 with the lr=4.463e-03 at step 0 in epoch 5\n",
      "8.072e-07 with the lr=3.906e-03 at step 2000 in epoch 5\n",
      "4.814e-07 with the lr=3.418e-03 at step 4000 in epoch 5\n",
      "Evaluation: 0.000991978131258116\n",
      "4.616e-07 with the lr=3.306e-03 at step 0 in epoch 6\n",
      "4.385e-07 with the lr=2.893e-03 at step 2000 in epoch 6\n",
      "1.340e-06 with the lr=2.532e-03 at step 4000 in epoch 6\n",
      "Evaluation: 0.001004201141238609\n",
      "4.406e-07 with the lr=2.449e-03 at step 0 in epoch 7\n",
      "2.595e-07 with the lr=2.143e-03 at step 2000 in epoch 7\n",
      "5.626e-07 with the lr=1.876e-03 at step 4000 in epoch 7\n",
      "Evaluation: 0.0013407421489547043\n",
      "6.481e-07 with the lr=1.814e-03 at step 0 in epoch 8\n",
      "3.726e-07 with the lr=1.588e-03 at step 2000 in epoch 8\n",
      "6.800e-07 with the lr=1.390e-03 at step 4000 in epoch 8\n",
      "Evaluation: 0.000629895685779318\n",
      "3.062e-07 with the lr=1.344e-03 at step 0 in epoch 9\n",
      "2.421e-07 with the lr=1.176e-03 at step 2000 in epoch 9\n",
      "4.559e-07 with the lr=1.029e-03 at step 4000 in epoch 9\n",
      "Evaluation: 0.0006757947585695828\n"
     ]
    }
   ],
   "source": [
    "logging_loss = 0\n",
    "logging_step = 2000\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    return x / min_max_value\n",
    "\n",
    "def evaluate(model,):\n",
    "    eval_log_loss = 0\n",
    "    for x, y in zip(*dataset.get_eval_data()):\n",
    "        x = normalize(x)\n",
    "        loss = model(x, y)[1]\n",
    "        eval_log_loss += loss\n",
    "    print(f\"Evaluation: {eval_log_loss.item()/ dataset.eval_len()}\")\n",
    "    \n",
    "for epoch in range(nb_epochs):\n",
    "    for idx, (x, y) in enumerate(zip(*dataset.get_train_data())):\n",
    "        x = normalize(x)\n",
    "        loss = model(x, y)[1]\n",
    "        model.backward()\n",
    "        adam.step()\n",
    "        scheduler.step()\n",
    "        logging_loss = loss.item()\n",
    "        if idx % logging_step == 0:\n",
    "            print(f\"{logging_loss/logging_step:.3e} with the lr={adam.lr:.3e} at step {idx} in epoch {epoch}\")\n",
    "            logging_loss = 0\n",
    "    evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c96ccc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10, 10, 1000)\n",
    "x = x.reshape(-1, 1)\n",
    "x_ = normalize(x)\n",
    "y_model = model(x_)[0]\n",
    "plt.plot(x, y_model, label=\"model\")\n",
    "plt.plot(x, np.sin(x), '.', label=\"sinus\", markersize=0.5)\n",
    "plt.xlim(-10,10)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc8d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
