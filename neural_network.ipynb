{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c47abf6",
   "metadata": {},
   "source": [
    "# Réseau de neurone from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aaf59a",
   "metadata": {},
   "source": [
    "## Définition des classes\n",
    "\n",
    "- Tensor (Trop compliqué car backend numpy en cpp)\n",
    "- Parameter\n",
    "- Function (forward / backward)\n",
    "- Linear\n",
    "- Couche\n",
    "- Adam\n",
    "- Réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9601a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab40253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter:\n",
    "    def __init__(self, data, requires_grad=True):\n",
    "        self._requires_grad = requires_grad\n",
    "        self._grad = None\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "256d75b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.modules = {}\n",
    "        self.parameters = []\n",
    "        self.fns = []\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    \n",
    "    def add_module(self, name, module):\n",
    "        if not isinstance(module, Module):\n",
    "            raise TypeError(\"module must be an instance of Module\")\n",
    "        self.modules.update({name: module})\n",
    "        self.parameters.extend(module.get_parameters())\n",
    "\n",
    "    def clear_fns(self):\n",
    "        self.fns = []\n",
    "\n",
    "    def register_parameter(self, parameter):\n",
    "        self.parameters.append(parameter)\n",
    "\n",
    "    def register_function(self, fn):\n",
    "        self.fns.append(fn)\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return self.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8037ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Function:\n",
    "    def __init__(self):\n",
    "        self._input = None\n",
    "        self._output = None\n",
    "        self._grad_input = None\n",
    "        self._grad_output = None\n",
    "\n",
    "    def forward(self, *args):\n",
    "        raise NotImplementedError(\"forward method not implemented\")\n",
    "    def backward(self, *args):\n",
    "        raise NotImplementedError(\"backward method not implemented\")\n",
    "    def __call__(self, *args):\n",
    "        self._input = args\n",
    "        self._output = self.forward(*args)\n",
    "        return self._output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc1b2a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Function):\n",
    "    def forward(self, x, y):\n",
    "        assert x.shape[-1] == y.shape[-1], f\"x and y must have the same shape but got {x.shape[-1]} and {y.shape[-1]}\"\n",
    "        return x + y\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output, grad_output.sum(axis=0)\n",
    "    \n",
    "class Mult(Function):\n",
    "    def forward(self, x, y):\n",
    "        assert x.shape[-1] == y.shape[-2], f\"impossible to compute matmult due to wrong shape (got {x.shape} and {y.shape})\"\n",
    "        self._input = (x, y)\n",
    "        output = x @ y\n",
    "        return output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        x, y = self._input\n",
    "        # grad_output (batch_size, out_features)\n",
    "        # x (batch_size, in_features)\n",
    "        # y (in_features, out_features)\n",
    "        grad_y = x.T @ grad_output / x.shape[0]\n",
    "        grad_x = grad_output @ y.T\n",
    "        return grad_x, grad_y\n",
    "    \n",
    "class ReLU(Function):\n",
    "    def __init__(self, eps=0):\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        self._input = x\n",
    "        return np.maximum(self.eps * x, x)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        x = self._input\n",
    "        grad_input = np.where(x > 0, grad_output, self.eps * grad_output)\n",
    "        return grad_input\n",
    "    \n",
    "class Identity(Function):\n",
    "    def forward(self, x):\n",
    "        self._input = x\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output    \n",
    "\n",
    "class Arctan(Function):\n",
    "    def forward(self, x):\n",
    "        self._input = x\n",
    "        return np.arctan(x)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        x = self._input\n",
    "        grad_input = grad_output / (1 + x**2)\n",
    "        return grad_input\n",
    "    \n",
    "class Tanh(Function):\n",
    "    def forward(self, x):\n",
    "        self._input = x\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        x = self._input\n",
    "        grad_input = grad_output * (1 - np.tanh(x)**2)\n",
    "        return grad_input\n",
    "    \n",
    "class MSELoss(Function):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        self._input = (y_pred, y_true)\n",
    "        return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    def backward(self, grad_output=1.0):\n",
    "        y_pred, y_true = self._input\n",
    "        grad_input = (2 * (y_pred - y_true)) / y_pred.shape[0]\n",
    "        return grad_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b9ba4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(np.random.normal(0, 0.1, size=(in_features, out_features)))\n",
    "        self.register_parameter(self.weight)\n",
    "        if bias:\n",
    "            self.bias = Parameter(np.random.normal(0, 0.1, size=(out_features)))\n",
    "            self.register_parameter(self.bias)\n",
    "        else:\n",
    "            self.bias = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, in_features)\n",
    "        # weight: (in_features, out_features)\n",
    "        # bias: (out_features,)\n",
    "        # output: (batch_size, out_features)\n",
    "        if self.bias is not None:\n",
    "            m = Mult()\n",
    "            self.register_function(m)\n",
    "            a = Add()\n",
    "            self.register_function(a)\n",
    "            res = m(x, self.weight.data)\n",
    "            res = a(res, self.bias.data)\n",
    "            return res\n",
    "        else:\n",
    "            m = Mult()\n",
    "            self.register_function(m)\n",
    "            res = m(x, self.weight.data)\n",
    "            return res\n",
    "        \n",
    "    def backward(self, grad_output):\n",
    "        if self.bias is not None:\n",
    "            dx, db = self.fns[-1].backward(grad_output)\n",
    "            dx, dw = self.fns[-2].backward(dx)\n",
    "            self.weight._grad = dw\n",
    "            self.bias._grad = db\n",
    "            self.clear_fns()\n",
    "            return dx\n",
    "        else:\n",
    "            dx, dw = self.fns[-1].backward(grad_output)\n",
    "            self.weight._grad = dw\n",
    "            self.clear_fns()\n",
    "            return dx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f673d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(Module):\n",
    "    def __init__(self, in_features, out_features, activation=None):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(in_features, out_features)\n",
    "        self.activation = ReLU() if activation is None else activation\n",
    "        self.add_module('linear', self.linear)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear.forward(x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        if self.activation is not None:\n",
    "            grad_output = self.activation.backward(grad_output)\n",
    "        dx = self.linear.backward(grad_output)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2f40422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, params, lr=0.001, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.m = [np.zeros_like(p) for p in params]\n",
    "        self.v = [np.zeros_like(p) for p in params]\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "        if len(self.params) == 0:\n",
    "            raise ValueError(\"No parameters to optimize\")\n",
    "        for i, p in enumerate(self.params):\n",
    "            if p._requires_grad:\n",
    "                if (p._grad == .0).all():\n",
    "                    print(\"Gradient is zero\")\n",
    "                grad = p._grad\n",
    "                self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * grad\n",
    "                self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * (grad ** 2)\n",
    "                m_hat = self.m[i] / (1 - self.beta1 ** self.t)\n",
    "                v_hat = self.v[i] / (1 - self.beta2 ** self.t)\n",
    "                update = self.lr * m_hat / (np.sqrt(v_hat) + self.eps)\n",
    "                assert p.data.shape == update.shape, f\"Shape mismatch: {p.data.shape} vs {update.shape}\"\n",
    "                p.data = p.data - update\n",
    "                p._grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0860ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(Module):\n",
    "    def __init__(self, nb_layers=4, in_features=1, out_features=1, hidden_features=16, activation=Arctan()):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        self.loss = MSELoss()\n",
    "        self.register_function(self.loss)\n",
    "        self.layers.append(Layer(in_features, hidden_features, activation))\n",
    "        for _ in range(nb_layers):\n",
    "            layer = Layer(hidden_features, hidden_features, activation)\n",
    "            self.layers.append(layer)\n",
    "        self.layers.append(Linear(hidden_features, out_features))\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            self.add_module(f'layer_{i}', layer)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        if y is not None:\n",
    "            loss = self.loss(x, y)\n",
    "            return x, loss\n",
    "        return x, None\n",
    "\n",
    "    def __call__(self, *args, **kwds):\n",
    "        return super().__call__(*args, **kwds)\n",
    "    \n",
    "    def backward(self):\n",
    "        grad_output = self.loss.backward()\n",
    "        for i, layer in enumerate(reversed(self.layers)):\n",
    "            grad_output = layer.backward(grad_output)\n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54e38cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[2 3]\n",
      " [3 4]\n",
      " [4 5]]\n",
      "Weight 0: [[1 2]\n",
      " [3 4]]\n",
      "Bias 0: [1 2]\n",
      "Weight 1: [[1]\n",
      " [2]]\n",
      "Bias 1: [-1]\n",
      "Output: [[3.51825074]\n",
      " [3.56668501]\n",
      " [3.59578859]]\n",
      "Target: [[3]\n",
      " [4]\n",
      " [5]]\n",
      "Loss: 0.809385127304723\n",
      "dx: [[ 0.00663508  0.01565291]\n",
      " [-0.00312664 -0.00737732]\n",
      " [-0.00649052 -0.01531557]]\n",
      "Weight 0 grad: [[-0.00264821 -0.00235454]\n",
      " [-0.00300681 -0.00267226]]\n",
      "Bias 0 grad: [-0.00107579 -0.00095315]\n",
      "Weight 1 grad: [[-0.44848938]\n",
      " [-0.45249809]]\n",
      "Bias 1 grad: [-0.8795171]\n",
      "Updated 0 Weight: [[1.00999996 2.00999996]\n",
      " [3.00999997 4.00999996]]\n",
      "Updated 0 Bias: [1.00999991 2.0099999 ]\n",
      "Updated 1 Weight: [[1.01]\n",
      " [2.01]]\n",
      "Updated 1 Bias: [-0.99]\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(nb_layers=0, in_features=2, out_features=1, hidden_features=2)\n",
    "layer0 = nn.layers[0]\n",
    "layer0.linear.weight.data = np.array([[1,2], [3,4]])\n",
    "layer0.linear.bias.data = np.array([1, 2])\n",
    "linear0 = layer0.linear\n",
    "layer1 = nn.layers[1]\n",
    "layer1.weight.data = np.array([[1], [2]])\n",
    "layer1.bias.data = np.array([-1])\n",
    "x = np.array([[2, 3], [3, 4], [4, 5]])\n",
    "y_hat = np.array([[3], [4], [5]])\n",
    "lin_adam = Adam(nn.get_parameters(), lr=0.01)\n",
    "y, l = nn(x, y_hat)\n",
    "print(f\"Input: {x}\")\n",
    "print(f\"Weight 0: {linear0.weight.data}\")\n",
    "print(f\"Bias 0: {linear0.bias.data}\")\n",
    "print(f\"Weight 1: {layer1.weight.data}\")\n",
    "print(f\"Bias 1: {layer1.bias.data}\")\n",
    "print(f\"Output: {y}\")\n",
    "print(f\"Target: {y_hat}\")\n",
    "dx = nn.backward()\n",
    "print(f\"Loss: {l}\")\n",
    "print(f\"dx: {dx}\")\n",
    "print(f\"Weight 0 grad: {linear0.weight._grad}\")\n",
    "print(f\"Bias 0 grad: {linear0.bias._grad}\")\n",
    "print(f\"Weight 1 grad: {layer1.weight._grad}\")\n",
    "print(f\"Bias 1 grad: {layer1.bias._grad}\")\n",
    "\n",
    "lin_adam.step()\n",
    "print(f\"Updated 0 Weight: {linear0.weight.data}\")\n",
    "print(f\"Updated 0 Bias: {linear0.bias.data}\")\n",
    "print(f\"Updated 1 Weight: {layer1.weight.data}\")\n",
    "print(f\"Updated 1 Bias: {layer1.bias.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79dc2ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7748949906420145\n",
      "Loss: 0.7438655833655426\n",
      "Loss: 0.7163406571799751\n",
      "Loss: 0.692334086527658\n",
      "Loss: 0.6718220061195076\n",
      "Loss: 0.6547360468498632\n",
      "Loss: 0.6409587593283992\n",
      "Loss: 0.6303183244120496\n",
      "Loss: 0.6225828865505684\n",
      "Loss: 0.6174582537581701\n",
      "Loss: 0.6145914139771483\n",
      "Loss: 0.6135809383391124\n",
      "Loss: 0.613994224592678\n",
      "Loss: 0.6153902373092016\n",
      "Loss: 0.617345177307065\n",
      "Loss: 0.6194776652292403\n",
      "Loss: 0.6214698495863692\n",
      "Loss: 0.6230815506707219\n",
      "Loss: 0.6241559821993176\n",
      "Loss: 0.6246172520860626\n",
      "Loss: 0.6244611774736547\n",
      "Loss: 0.6237416425488344\n",
      "Loss: 0.6225547850430555\n",
      "Loss: 0.6210229301056177\n",
      "Loss: 0.6192796537292564\n",
      "Loss: 0.6174568422251826\n",
      "Loss: 0.615674213092717\n",
      "Loss: 0.6140314921146787\n",
      "Loss: 0.6126032741189508\n",
      "Loss: 0.6114364883114171\n",
      "Loss: 0.6105503046221888\n",
      "Loss: 0.6099382292371655\n",
      "Loss: 0.6095720361186397\n",
      "Loss: 0.609407073848565\n",
      "Loss: 0.609388393019379\n",
      "Loss: 0.609457083555524\n",
      "Loss: 0.6095562152300903\n",
      "Loss: 0.6096358481103072\n",
      "Loss: 0.6096567165867827\n",
      "Loss: 0.609592369995532\n",
      "Loss: 0.6094297448385548\n",
      "Loss: 0.6091683181287154\n",
      "Loss: 0.6088181253683994\n",
      "Loss: 0.6083970080570186\n",
      "Loss: 0.6079274833213771\n",
      "Loss: 0.6074336093116347\n",
      "Loss: 0.6069381657173717\n",
      "Loss: 0.6064603914164334\n",
      "Loss: 0.6060144321242259\n",
      "Loss: 0.6056085594720676\n",
      "Loss: 0.6052451370884313\n",
      "Loss: 0.6049212355736543\n",
      "Loss: 0.6046297421718109\n",
      "Loss: 0.6043607764601291\n",
      "Loss: 0.6041032125515872\n",
      "Loss: 0.6038461207069429\n",
      "Loss: 0.6035799737358495\n",
      "Loss: 0.6032975105774298\n",
      "Loss: 0.6029942038423403\n",
      "Loss: 0.6026683322947467\n",
      "Loss: 0.6023207064489445\n",
      "Loss: 0.6019541305738626\n",
      "Loss: 0.6015727046174929\n",
      "Loss: 0.6011810743846996\n",
      "Loss: 0.6007837292494792\n",
      "Loss: 0.6003844267709236\n",
      "Loss: 0.5999857967062807\n",
      "Loss: 0.5995891472611964\n",
      "Loss: 0.5991944679537702\n",
      "Loss: 0.5988005995298589\n",
      "Loss: 0.5984055243510887\n",
      "Loss: 0.598006721862258\n",
      "Loss: 0.5976015332382268\n",
      "Loss: 0.597187486139728\n",
      "Loss: 0.5967625428470732\n",
      "Loss: 0.5963252505410285\n",
      "Loss: 0.595874788666325\n",
      "Loss: 0.5954109228706953\n",
      "Loss: 0.5949338862010544\n",
      "Loss: 0.5944442149965934\n",
      "Loss: 0.5939425689394912\n",
      "Loss: 0.593429562397477\n",
      "Loss: 0.5929056284550285\n",
      "Loss: 0.5923709291600042\n",
      "Loss: 0.5918253169084003\n",
      "Loss: 0.5912683438605488\n",
      "Loss: 0.5906993098781007\n",
      "Loss: 0.5901173353720339\n",
      "Loss: 0.5895214439174865\n",
      "Loss: 0.5889106403789891\n",
      "Loss: 0.5882839731256863\n",
      "Loss: 0.5876405730071418\n",
      "Loss: 0.5869796663236803\n",
      "Loss: 0.5863005633165336\n",
      "Loss: 0.5856026271222204\n",
      "Loss: 0.5848852302969434\n",
      "Loss: 0.5841477067779505\n",
      "Loss: 0.5833893065986994\n",
      "Loss: 0.582609159087601\n",
      "Loss: 0.5818062480488595\n",
      "Loss: 0.5809793999829724\n",
      "Loss: 0.5801272841576668\n",
      "Loss: 0.5792484216034729\n",
      "Loss: 0.5783411990723755\n",
      "Loss: 0.5774038837172045\n",
      "Loss: 0.5764346346510265\n",
      "Loss: 0.5754315084602459\n",
      "Loss: 0.5743924569460502\n",
      "Loss: 0.5733153166172362\n",
      "Loss: 0.572197790541659\n",
      "Loss: 0.5710374239292323\n",
      "Loss: 0.5698315751861561\n",
      "Loss: 0.5685773841438894\n",
      "Loss: 0.5672717387887559\n",
      "Loss: 0.5659112412067611\n",
      "Loss: 0.5644921727421833\n",
      "Loss: 0.5630104576738707\n",
      "Loss: 0.5614616241422616\n",
      "Loss: 0.5598407606784476\n",
      "Loss: 0.5581424665169116\n",
      "Loss: 0.5563607938997928\n",
      "Loss: 0.5544891807566583\n",
      "Loss: 0.5525203724088268\n",
      "Loss: 0.5504463312409112\n",
      "Loss: 0.548258133561273\n",
      "Loss: 0.5459458531246137\n",
      "Loss: 0.5434984310442396\n",
      "Loss: 0.5409035321619061\n",
      "Loss: 0.5381473885190148\n",
      "Loss: 0.5352146316179848\n",
      "Loss: 0.5320881170264594\n",
      "Loss: 0.5287487480775542\n",
      "Loss: 0.5251753107294096\n",
      "Loss: 0.5213443402289433\n",
      "Loss: 0.5172300538251634\n",
      "Loss: 0.5128044049884087\n",
      "Loss: 0.5080373471117458\n",
      "Loss: 0.50289744331547\n",
      "Loss: 0.4973530285820969\n",
      "Loss: 0.4913742210262189\n",
      "Loss: 0.48493616940343415\n",
      "Loss: 0.4780239210155628\n",
      "Loss: 0.4706388883312687\n",
      "Loss: 0.46280518488626515\n",
      "Loss: 0.4545689306724217\n",
      "Loss: 0.44597229372364516\n",
      "Loss: 0.4369767991956566\n",
      "Loss: 0.4273711166671057\n",
      "Loss: 0.4168501657640152\n",
      "Loss: 0.40531352702303797\n",
      "Loss: 0.39301317663013585\n",
      "Loss: 0.3803553686335779\n",
      "Loss: 0.3675746800061484\n",
      "Loss: 0.3545925927997624\n",
      "Loss: 0.3411999619167607\n",
      "Loss: 0.32738707800736666\n",
      "Loss: 0.31344778967686304\n",
      "Loss: 0.2995967831144086\n",
      "Loss: 0.2855715679811899\n",
      "Loss: 0.2710842652194642\n",
      "Loss: 0.2563935305341495\n",
      "Loss: 0.24193766290989227\n",
      "Loss: 0.22768297593658224\n",
      "Loss: 0.21342628892527418\n",
      "Loss: 0.1993873457273092\n",
      "Loss: 0.18582292028235958\n",
      "Loss: 0.17251780958660648\n",
      "Loss: 0.15944318995516749\n",
      "Loss: 0.1469569767489491\n",
      "Loss: 0.13499545835046214\n",
      "Loss: 0.12344960977211339\n",
      "Loss: 0.11258263155520992\n",
      "Loss: 0.10230906857932194\n",
      "Loss: 0.09255074184884969\n",
      "Loss: 0.08353191693237605\n",
      "Loss: 0.07509916513710178\n",
      "Loss: 0.06729197729088737\n",
      "Loss: 0.06017962863507828\n",
      "Loss: 0.05360417438679727\n",
      "Loss: 0.04769835676926044\n",
      "Loss: 0.0423416349162996\n",
      "Loss: 0.03754580932892219\n",
      "Loss: 0.03330067004828627\n",
      "Loss: 0.029513571156993476\n",
      "Loss: 0.026236173571099794\n",
      "Loss: 0.023345049473217788\n",
      "Loss: 0.02088725750537732\n",
      "Loss: 0.01875507080154207\n",
      "Loss: 0.016970518450122273\n",
      "Loss: 0.015456655373715064\n",
      "Loss: 0.01420913836670539\n",
      "Loss: 0.013176510974030919\n",
      "Loss: 0.012339443594434979\n",
      "Loss: 0.0116647049029239\n",
      "Loss: 0.011127004867134574\n",
      "Loss: 0.010704016906967366\n",
      "Loss: 0.010371191579771162\n",
      "Loss: 0.010112996424958644\n",
      "Loss: 0.009909299694512137\n",
      "Loss: 0.009748247022990349\n",
      "Loss: 0.0096157229568674\n",
      "Loss: 0.009502037493110968\n",
      "Loss: 0.009399536954528099\n",
      "Loss: 0.009299318169386082\n",
      "Loss: 0.009199692652796522\n",
      "Loss: 0.009092194697159196\n",
      "Loss: 0.008980086138726582\n",
      "Loss: 0.00885486263691112\n",
      "Loss: 0.008723326134216024\n",
      "Loss: 0.008577606750184503\n",
      "Loss: 0.00842611360672947\n",
      "Loss: 0.008262027111347076\n",
      "Loss: 0.00809362400887685\n",
      "Loss: 0.007916418505874245\n",
      "Loss: 0.007736522408694095\n",
      "Loss: 0.00755232308566165\n",
      "Loss: 0.007367014203447534\n",
      "Loss: 0.007182058515488213\n",
      "Loss: 0.006997433705796298\n",
      "Loss: 0.006816692909015479\n",
      "Loss: 0.0066381676188893846\n",
      "Loss: 0.006465553214958758\n",
      "Loss: 0.006297190348922177\n",
      "Loss: 0.00613526680980039\n",
      "Loss: 0.005979672018344013\n",
      "Loss: 0.0058301943338514755\n",
      "Loss: 0.005688139314428297\n",
      "Loss: 0.005552092105760484\n",
      "Loss: 0.005423258338719951\n",
      "Loss: 0.005300605105135869\n",
      "Loss: 0.005184072864230471\n",
      "Loss: 0.0050737938888688475\n",
      "Loss: 0.004968570615633608\n",
      "Loss: 0.004868841886757719\n",
      "Loss: 0.004773730386142958\n",
      "Loss: 0.004682808613905264\n",
      "Loss: 0.004596062998021899\n",
      "Loss: 0.004512579708992306\n",
      "Loss: 0.004432357283741307\n",
      "Loss: 0.004354965135477063\n",
      "Loss: 0.004279866380439318\n",
      "Loss: 0.004207101753511393\n",
      "Loss: 0.004136159625821027\n",
      "Loss: 0.004066828817798618\n",
      "Loss: 0.003999091696687541\n",
      "Loss: 0.003932548373517377\n",
      "Loss: 0.0038671666483506627\n",
      "Loss: 0.0038029031966099122\n",
      "Loss: 0.0037395032469716137\n",
      "Loss: 0.0036770132006512407\n",
      "Loss: 0.003615402849212654\n",
      "Loss: 0.003554527669694584\n",
      "Loss: 0.0034944605901992116\n",
      "Loss: 0.003435197645634279\n",
      "Loss: 0.0033766600601955223\n",
      "Loss: 0.003318920219604848\n",
      "Loss: 0.003261996028096067\n",
      "Loss: 0.0032058413527463804\n",
      "Loss: 0.003150512367382416\n",
      "Loss: 0.0030960385949163837\n",
      "Loss: 0.003042388180277907\n",
      "Loss: 0.002989592508494924\n",
      "Loss: 0.002937682295866209\n",
      "Loss: 0.0028866334436651064\n",
      "Loss: 0.0028364508324374717\n",
      "Loss: 0.0027871571400234735\n",
      "Loss: 0.002738735966436981\n",
      "Loss: 0.00269117130578015\n",
      "Loss: 0.0026444705667284796\n",
      "Loss: 0.00259862510342363\n",
      "Loss: 0.002553609547408916\n",
      "Loss: 0.0025094135104376347\n",
      "Loss: 0.0024660317138579277\n",
      "Loss: 0.0024234415050750657\n",
      "Loss: 0.002381620095141928\n",
      "Loss: 0.002340558019785794\n",
      "Loss: 0.002300240296488341\n",
      "Loss: 0.002260643365242554\n",
      "Loss: 0.0022217502663898574\n",
      "Loss: 0.0021835489898987\n",
      "Loss: 0.0021460236923873106\n",
      "Loss: 0.0021091556140850685\n",
      "Loss: 0.002072929840361827\n",
      "Loss: 0.0020373358526148866\n",
      "Loss: 0.0020023602518535392\n",
      "Loss: 0.0019679877993667295\n",
      "Loss: 0.0019342069294731306\n",
      "Loss: 0.0019010078666610076\n",
      "Loss: 0.001868380233712597\n",
      "Loss: 0.0018363125458104226\n",
      "Loss: 0.0018047940852722487\n",
      "Loss: 0.0017738166189752837\n",
      "Loss: 0.001743371561340336\n",
      "Loss: 0.001713449471091041\n",
      "Loss: 0.0016840411843735213\n",
      "Loss: 0.0016551380891816614\n",
      "Loss: 0.0016267326523386383\n",
      "Loss: 0.001598816799820481\n",
      "Loss: 0.0015713819914589802\n",
      "Loss: 0.0015444200218845527\n",
      "Loss: 0.0015179228264204155\n",
      "Loss: 0.0014918829582167472\n",
      "Loss: 0.0014662926516200846\n",
      "Loss: 0.001441143955191488\n",
      "Loss: 0.001416429052484132\n",
      "Loss: 0.001392140118233311\n",
      "Loss: 0.001368269821731141\n",
      "Loss: 0.0013448107221991294\n",
      "Loss: 0.0013217554801809896\n",
      "Loss: 0.0012990967634689053\n",
      "Loss: 0.001276827240915018\n",
      "Loss: 0.0012549399156463385\n",
      "Loss: 0.0012334277953166327\n",
      "Loss: 0.0012122841987514045\n",
      "Loss: 0.0011915024420331088\n",
      "Loss: 0.0011710759960803555\n",
      "Loss: 0.0011509984536160508\n",
      "Loss: 0.0011312634828433631\n",
      "Loss: 0.0011118649980261929\n",
      "Loss: 0.001092796948074553\n",
      "Loss: 0.0010740535427252755\n",
      "Loss: 0.001055629015481785\n",
      "Loss: 0.001037517810064588\n",
      "Loss: 0.0010197144236233004\n",
      "Loss: 0.0010022135032276642\n",
      "Loss: 0.0009850097951729236\n",
      "Loss: 0.0009680981432563687\n",
      "Loss: 0.0009514735262917199\n",
      "Loss: 0.0009351309792336261\n",
      "Loss: 0.0009190656924309352\n",
      "Loss: 0.0009032728817903332\n",
      "Loss: 0.0008877479306854305\n",
      "Loss: 0.0008724862241948475\n",
      "Loss: 0.0008574833285874877\n",
      "Loss: 0.0008427347886933476\n",
      "Loss: 0.0008282363582228707\n",
      "Loss: 0.0008139837435587387\n",
      "Loss: 0.0007999729260671202\n",
      "Loss: 0.000786199823818453\n",
      "Loss: 0.0007726608096862772\n",
      "Loss: 0.0007593522828148567\n",
      "Loss: 0.0007462716889451993\n",
      "Loss: 0.0007334172283369996\n",
      "Loss: 0.0007207905318555598\n",
      "Loss: 0.0007083982808408101\n",
      "Loss: 0.0006962619045673105\n",
      "Loss: 0.0006844325080867553\n",
      "Loss: 0.0006730363716355359\n",
      "Loss: 0.0006623756646095044\n",
      "Loss: 0.0006531749612746675\n",
      "Loss: 0.0006472331074519875\n",
      "Loss: 0.0006487250573648555\n",
      "Loss: 0.0006678947422879853\n",
      "Loss: 0.0007230869050924965\n",
      "Loss: 0.0008425767340156458\n",
      "Loss: 0.000979569389675589\n",
      "Loss: 0.0009822774310139456\n",
      "Loss: 0.0007134634496354628\n",
      "Loss: 0.0005565291357767969\n",
      "Loss: 0.0006977737078806417\n",
      "Loss: 0.0007697532931123362\n",
      "Loss: 0.0006000827421880456\n",
      "Loss: 0.0005303622332509919\n",
      "Loss: 0.0006489545333585202\n",
      "Loss: 0.0006228035116130659\n",
      "Loss: 0.0004967926051680798\n",
      "Loss: 0.0005439021276849415\n",
      "Loss: 0.0005872072470113845\n",
      "Loss: 0.0004899680576537297\n",
      "Loss: 0.0004793213058681787\n",
      "Loss: 0.0005332763619782494\n",
      "Loss: 0.000478155227410226\n",
      "Loss: 0.0004406891940973835\n",
      "Loss: 0.00048144382162042536\n",
      "Loss: 0.0004588796525979884\n",
      "Loss: 0.0004154248547792047\n",
      "Loss: 0.00043751193785223404\n",
      "Loss: 0.0004349604533688946\n",
      "Loss: 0.0003964955477493417\n",
      "Loss: 0.0004018540943601419\n",
      "Loss: 0.00040891516670699325\n",
      "Loss: 0.0003801814899740677\n",
      "Loss: 0.00037336536696244905\n",
      "Loss: 0.0003824778363985863\n",
      "Loss: 0.00036441477890867814\n",
      "Loss: 0.0003506504117487998\n",
      "Loss: 0.0003569346946086238\n",
      "Loss: 0.0003480435325371644\n",
      "Loss: 0.00033224811425450527\n",
      "Loss: 0.0003333328190334923\n",
      "Loss: 0.00033061208074941327\n",
      "Loss: 0.0003166457231264931\n",
      "Loss: 0.00031244949330741387\n",
      "Loss: 0.0003123221631940708\n",
      "Loss: 0.0003023667136020059\n",
      "Loss: 0.0002946049619103227\n",
      "Loss: 0.00029394169475636034\n",
      "Loss: 0.0002882084617655102\n",
      "Loss: 0.00027948356210033787\n",
      "Loss: 0.0002765209974840697\n",
      "Loss: 0.0002735563491984443\n",
      "Loss: 0.0002661662493124108\n",
      "Loss: 0.00026092129379425125\n",
      "Loss: 0.00025857146510868174\n",
      "Loss: 0.0002535012209794075\n",
      "Loss: 0.0002473557632811125\n",
      "Loss: 0.00024402305901244465\n",
      "Loss: 0.0002406994120110528\n",
      "Loss: 0.00023526796400319462\n",
      "Loss: 0.00023072748972547338\n",
      "Loss: 0.00022776177896876725\n",
      "Loss: 0.00022373991041698836\n",
      "Loss: 0.00021892002516503493\n",
      "Loss: 0.0002153306302186328\n",
      "Loss: 0.00021220027387659911\n",
      "Loss: 0.0002081007378629574\n",
      "Loss: 0.0002040010950472295\n",
      "Loss: 0.00020081997417999433\n",
      "Loss: 0.00019757340117374433\n",
      "Loss: 0.00019372322408004017\n",
      "Loss: 0.0001901600517539032\n",
      "Loss: 0.00018715491515386952\n",
      "Loss: 0.00018394874883675117\n",
      "Loss: 0.0001804332855847282\n",
      "Loss: 0.00017722762719430145\n",
      "Loss: 0.00017434548137663344\n",
      "Loss: 0.0001712876552195223\n",
      "Loss: 0.00016808345823826195\n",
      "Loss: 0.00016512874560360095\n",
      "Loss: 0.0001623763342208048\n",
      "Loss: 0.000159509879502656\n",
      "Loss: 0.00015657308409228733\n",
      "Loss: 0.00015381666614667299\n",
      "Loss: 0.0001512059886837008\n",
      "Loss: 0.0001485384529403424\n",
      "Loss: 0.00014583251779841196\n",
      "Loss: 0.00014324945638045136\n",
      "Loss: 0.00014078434567886184\n",
      "Loss: 0.00013830680016426006\n",
      "Loss: 0.00013580625657438945\n",
      "Loss: 0.0001333842520902041\n",
      "Loss: 0.00013106137389386994\n",
      "Loss: 0.0001287585926576007\n",
      "Loss: 0.00012644544667974903\n",
      "Loss: 0.0001241781679472927\n",
      "Loss: 0.00012199102241186459\n",
      "Loss: 0.00011984545801711451\n",
      "Loss: 0.00011770437690092986\n",
      "Loss: 0.00011558847105259009\n",
      "Loss: 0.0001135315553468282\n",
      "Loss: 0.00011152565151446874\n",
      "Loss: 0.00010954067507412851\n",
      "Loss: 0.00010757273569159604\n",
      "Loss: 0.00010564367293724027\n",
      "Loss: 0.00010376312324117002\n",
      "Loss: 0.0001019164321625977\n",
      "Loss: 0.00010008973351895189\n",
      "Loss: 9.828840593808766e-05\n",
      "Loss: 9.652494719264864e-05\n",
      "Loss: 9.479962127736663e-05\n",
      "Loss: 9.310196898813767e-05\n",
      "Loss: 9.142637549467679e-05\n",
      "Loss: 8.977774648372968e-05\n",
      "Loss: 8.816233309686805e-05\n",
      "Loss: 8.657877088090953e-05\n",
      "Loss: 8.502081816855775e-05\n",
      "Loss: 8.348564119322389e-05\n",
      "Loss: 8.197598103594314e-05\n",
      "Loss: 8.049513332804997e-05\n",
      "Loss: 7.904232360808605e-05\n",
      "Loss: 7.761397979993798e-05\n",
      "Loss: 7.620801581909081e-05\n",
      "Loss: 7.482539335180762e-05\n",
      "Loss: 7.346794798285811e-05\n",
      "Loss: 7.213568314034983e-05\n",
      "Loss: 7.082673083421517e-05\n",
      "Loss: 6.953935997453741e-05\n",
      "Loss: 6.827335198148164e-05\n",
      "Loss: 6.702953048310974e-05\n",
      "Loss: 6.580828386846718e-05\n",
      "Loss: 6.460890941335693e-05\n",
      "Loss: 6.343019359166994e-05\n",
      "Loss: 6.227134870954004e-05\n",
      "Loss: 6.113235714507953e-05\n",
      "Loss: 6.0013475928737e-05\n",
      "Loss: 5.891464184176287e-05\n",
      "Loss: 5.783529354611884e-05\n",
      "Loss: 5.677468889519723e-05\n",
      "Loss: 5.5732320709774514e-05\n",
      "Loss: 5.470801308564883e-05\n",
      "Loss: 5.370174755557893e-05\n",
      "Loss: 5.2713382245175374e-05\n",
      "Loss: 5.174255903973242e-05\n",
      "Loss: 5.078880207943268e-05\n",
      "Loss: 4.985168078924381e-05\n",
      "Loss: 4.8930915578815455e-05\n",
      "Loss: 4.8026331562891594e-05\n",
      "Loss: 4.7137770655073176e-05\n",
      "Loss: 4.6265002446366004e-05\n",
      "Loss: 4.5407719063810056e-05\n",
      "Loss: 4.456558369725879e-05\n",
      "Loss: 4.373828338095565e-05\n",
      "Loss: 4.292556523110096e-05\n",
      "Loss: 4.212721667840427e-05\n",
      "Loss: 4.134304206653491e-05\n",
      "Loss: 4.057282727369167e-05\n",
      "Loss: 3.981633398251996e-05\n",
      "Loss: 3.9073307229454906e-05\n",
      "Loss: 3.834349097984602e-05\n",
      "Loss: 3.762664593652121e-05\n",
      "Loss: 3.6922549256278334e-05\n",
      "Loss: 3.6230996307721535e-05\n",
      "Loss: 3.555178706369849e-05\n",
      "Loss: 3.488472334581964e-05\n",
      "Loss: 3.4229601839826877e-05\n",
      "Loss: 3.3586216367088654e-05\n",
      "Loss: 3.2954360397812786e-05\n",
      "Loss: 3.233382954633871e-05\n",
      "Loss: 3.172442602757378e-05\n",
      "Loss: 3.112595680720977e-05\n",
      "Loss: 3.0538236367129575e-05\n",
      "Loss: 2.996108223474246e-05\n",
      "Loss: 2.9394316901626194e-05\n",
      "Loss: 2.8837764016016e-05\n",
      "Loss: 2.8291250269297596e-05\n",
      "Loss: 2.7754603475941144e-05\n",
      "Loss: 2.7227654012431792e-05\n",
      "Loss: 2.6710234391068495e-05\n",
      "Loss: 2.6202179696833498e-05\n",
      "Loss: 2.5703328033515913e-05\n",
      "Loss: 2.5213519928180107e-05\n",
      "Loss: 2.4732599314464924e-05\n",
      "Loss: 2.426041222392664e-05\n",
      "Loss: 2.379680816146402e-05\n",
      "Loss: 2.334163840977034e-05\n",
      "Loss: 2.289475770877395e-05\n",
      "Loss: 2.245602235912343e-05\n",
      "Loss: 2.202529216005658e-05\n",
      "Loss: 2.1602428370535093e-05\n",
      "Loss: 2.1187295944959754e-05\n",
      "Loss: 2.077976134676703e-05\n",
      "Loss: 2.037969526856659e-05\n",
      "Loss: 1.9986970317549123e-05\n",
      "Loss: 1.9601464690206617e-05\n",
      "Loss: 1.922305997738213e-05\n",
      "Loss: 1.885164695800737e-05\n",
      "Loss: 1.848712465414085e-05\n",
      "Loss: 1.8129411414476145e-05\n",
      "Loss: 1.7778449494700855e-05\n",
      "Loss: 1.7434230988646443e-05\n",
      "Loss: 1.7096823443871927e-05\n",
      "Loss: 1.6766441934611812e-05\n",
      "Loss: 1.6443552426832474e-05\n",
      "Loss: 1.612909935205448e-05\n",
      "Loss: 1.5824900150950936e-05\n",
      "Loss: 1.55344312703163e-05\n",
      "Loss: 1.526434864931699e-05\n",
      "Loss: 1.5027382706649325e-05\n",
      "Loss: 1.4848394366229105e-05\n",
      "Loss: 1.4775544329535357e-05\n",
      "Loss: 1.4905438642131317e-05\n",
      "Loss: 1.5427353974930052e-05\n",
      "Loss: 1.6731806581607568e-05\n",
      "Loss: 1.9581905198477072e-05\n",
      "Loss: 2.5586219929084742e-05\n",
      "Loss: 3.773306316490362e-05\n",
      "Loss: 6.218611905955654e-05\n",
      "Loss: 0.00010776115719218298\n",
      "Loss: 0.00018800167160499672\n",
      "Loss: 0.0002933278026236457\n",
      "Loss: 0.00038142558956994117\n",
      "Loss: 0.00032679669239481945\n",
      "Loss: 0.00014671591906864598\n",
      "Loss: 1.4715124621707211e-05\n",
      "Loss: 6.717771076325714e-05\n",
      "Loss: 0.00018463524752575025\n",
      "Loss: 0.00017178050965015027\n",
      "Loss: 5.423590188094909e-05\n",
      "Loss: 1.39342075352702e-05\n",
      "Loss: 8.791997769031423e-05\n",
      "Loss: 0.0001239832100658809\n",
      "Loss: 5.5612780964239826e-05\n",
      "Loss: 9.243192747267238e-06\n",
      "Loss: 5.095803400355021e-05\n",
      "Loss: 8.247554894282238e-05\n",
      "Loss: 4.3065332781344516e-05\n",
      "Loss: 8.521933243718446e-06\n",
      "Loss: 3.418594190021657e-05\n",
      "Loss: 5.7151420303052584e-05\n",
      "Loss: 3.0738459388689106e-05\n",
      "Loss: 7.87293002570347e-06\n",
      "Loss: 2.5164762350074285e-05\n",
      "Loss: 3.9533801132498335e-05\n",
      "Loss: 2.200238078208969e-05\n",
      "Loss: 7.274912981512302e-06\n",
      "Loss: 1.9035040142709984e-05\n",
      "Loss: 2.8358475490184043e-05\n",
      "Loss: 1.62381168348664e-05\n",
      "Loss: 6.72711783388175e-06\n",
      "Loss: 1.4621018409496591e-05\n",
      "Loss: 2.053837625335271e-05\n",
      "Loss: 1.2614482979002373e-05\n",
      "Loss: 6.210914540842118e-06\n",
      "Loss: 1.1248594086220903e-05\n",
      "Loss: 1.5380553032549533e-05\n",
      "Loss: 1.027047083327413e-05\n",
      "Loss: 5.7420587566548525e-06\n",
      "Loss: 8.745958789128932e-06\n",
      "Loss: 1.1717744202360684e-05\n",
      "Loss: 8.697631824434944e-06\n",
      "Loss: 5.347230987349312e-06\n",
      "Loss: 6.897598660554021e-06\n",
      "Loss: 9.150478014998949e-06\n",
      "Loss: 7.535847414176134e-06\n",
      "Loss: 5.03367699487751e-06\n",
      "Loss: 5.580679962561788e-06\n",
      "Loss: 7.2355299017842775e-06\n",
      "Loss: 6.605441312741926e-06\n",
      "Loss: 4.788968858396768e-06\n",
      "Loss: 4.67885614016746e-06\n",
      "Loss: 5.806170239368289e-06\n",
      "Loss: 5.776937768570184e-06\n",
      "Loss: 4.572413447137606e-06\n",
      "Loss: 4.096598517552322e-06\n",
      "Loss: 4.727679629212396e-06\n",
      "Loss: 5.010932573187678e-06\n",
      "Loss: 4.337117791650708e-06\n",
      "Loss: 3.7436860613156824e-06\n",
      "Loss: 3.948817748109394e-06\n",
      "Loss: 4.2943928879536524e-06\n",
      "Loss: 4.042339575684343e-06\n",
      "Loss: 3.5249703412042603e-06\n",
      "Loss: 3.424615921695904e-06\n",
      "Loss: 3.6635677654948657e-06\n",
      "Loss: 3.673393492253816e-06\n",
      "Loss: 3.3460836778548197e-06\n",
      "Loss: 3.1005478750734063e-06\n",
      "Loss: 3.1588107755924576e-06\n",
      "Loss: 3.258976582741739e-06\n",
      "Loss: 3.133262932527873e-06\n",
      "Loss: 2.89661356145631e-06\n",
      "Loss: 2.8037835589325104e-06\n",
      "Loss: 2.858901427827194e-06\n",
      "Loss: 2.8598842118709535e-06\n",
      "Loss: 2.722776612778674e-06\n",
      "Loss: 2.57483506834617e-06\n",
      "Loss: 2.5358112376941773e-06\n",
      "Loss: 2.5557216941249192e-06\n",
      "Loss: 2.5169350001969253e-06\n",
      "Loss: 2.4059027392975805e-06\n",
      "Loss: 2.3102185828970483e-06\n",
      "Loss: 2.2819026857910936e-06\n",
      "Loss: 2.2763750960507803e-06\n",
      "Loss: 2.230042059167552e-06\n",
      "Loss: 2.1460107060783577e-06\n",
      "Loss: 2.0765491101249793e-06\n",
      "Loss: 2.0466999047435966e-06\n",
      "Loss: 2.0283797801626713e-06\n",
      "Loss: 1.9861395659563533e-06\n",
      "Loss: 1.922276578698025e-06\n",
      "Loss: 1.8662943637646262e-06\n",
      "Loss: 1.8335508724711396e-06\n",
      "Loss: 1.8097387283933743e-06\n",
      "Loss: 1.773930902053817e-06\n",
      "Loss: 1.7244836882795896e-06\n",
      "Loss: 1.6769644124144796e-06\n",
      "Loss: 1.6426178827545382e-06\n",
      "Loss: 1.6164163420213676e-06\n",
      "Loss: 1.5860741616304673e-06\n",
      "Loss: 1.5472440333710762e-06\n",
      "Loss: 1.5066622255008277e-06\n",
      "Loss: 1.4724481412280726e-06\n",
      "Loss: 1.4450152476118499e-06\n",
      "Loss: 1.4182117789185359e-06\n",
      "Loss: 1.3871808514009663e-06\n",
      "Loss: 1.3531595374528584e-06\n",
      "Loss: 1.320903363561204e-06\n",
      "Loss: 1.2930707144128045e-06\n",
      "Loss: 1.2679576209372968e-06\n",
      "Loss: 1.2421022557168249e-06\n",
      "Loss: 1.2140601106545016e-06\n",
      "Loss: 1.1853733967881025e-06\n",
      "Loss: 1.1584430776571257e-06\n",
      "Loss: 1.1340492699286303e-06\n",
      "Loss: 1.1109499710958534e-06\n",
      "Loss: 1.087451109912081e-06\n",
      "Loss: 1.0630429425589928e-06\n",
      "Loss: 1.0385986025911374e-06\n",
      "Loss: 1.0152903743357838e-06\n",
      "Loss: 9.934853816394814e-07\n",
      "Loss: 9.725904620488648e-07\n",
      "Loss: 9.517569213886392e-07\n",
      "Loss: 9.306426620792657e-07\n",
      "Loss: 9.095792405795067e-07\n",
      "Loss: 8.891471128405264e-07\n",
      "Loss: 8.696461410058599e-07\n",
      "Loss: 8.50911082758071e-07\n",
      "Loss: 8.325351442805039e-07\n",
      "Loss: 8.142293549492547e-07\n",
      "Loss: 7.960092809443132e-07\n",
      "Loss: 7.781106734199529e-07\n",
      "Loss: 7.607622635468852e-07\n",
      "Loss: 7.440169126739984e-07\n",
      "Loss: 7.277475871206032e-07\n",
      "Loss: 7.117704315017116e-07\n",
      "Loss: 6.959781947912058e-07\n",
      "Loss: 6.803902027911214e-07\n",
      "Loss: 6.651067896636286e-07\n",
      "Loss: 6.50221685687002e-07\n",
      "Loss: 6.357599049409836e-07\n",
      "Loss: 6.216736162288818e-07\n",
      "Loss: 6.07883890128673e-07\n",
      "Loss: 5.943311857770407e-07\n",
      "Loss: 5.810020009297438e-07\n",
      "Loss: 5.679226452538023e-07\n",
      "Loss: 5.551319263190954e-07\n",
      "Loss: 5.426539372637056e-07\n",
      "Loss: 5.304855268420737e-07\n",
      "Loss: 5.186014409200906e-07\n",
      "Loss: 5.06969626259512e-07\n",
      "Loss: 4.955660663236128e-07\n",
      "Loss: 4.843820220248057e-07\n",
      "Loss: 4.7342201043201925e-07\n",
      "Loss: 4.6269629235498714e-07\n",
      "Loss: 4.5221264065035205e-07\n",
      "Loss: 4.4197151958960935e-07\n",
      "Loss: 4.31965670039536e-07\n",
      "Loss: 4.221831050999941e-07\n",
      "Loss: 4.1261126287607624e-07\n",
      "Loss: 4.0324024804612444e-07\n",
      "Loss: 3.940642544387454e-07\n",
      "Loss: 3.8508103337249025e-07\n",
      "Loss: 3.762903426472342e-07\n",
      "Loss: 3.6769209494223474e-07\n",
      "Loss: 3.5928507979569076e-07\n",
      "Loss: 3.5106639712284486e-07\n",
      "Loss: 3.430316462969779e-07\n",
      "Loss: 3.351755173911558e-07\n",
      "Loss: 3.274924898802051e-07\n",
      "Loss: 3.1997740990293824e-07\n",
      "Loss: 3.1262578159239664e-07\n",
      "Loss: 3.054338474990414e-07\n",
      "Loss: 2.9839843681308134e-07\n",
      "Loss: 2.9151677993505843e-07\n",
      "Loss: 2.8478626693612287e-07\n",
      "Loss: 2.782043053291764e-07\n",
      "Loss: 2.717682022273999e-07\n",
      "Loss: 2.6547515103241135e-07\n",
      "Loss: 2.5932223287859585e-07\n",
      "Loss: 2.5330646905537307e-07\n",
      "Loss: 2.474248623583706e-07\n",
      "Loss: 2.416744445388049e-07\n",
      "Loss: 2.3605230706282933e-07\n",
      "Loss: 2.3055561887477903e-07\n",
      "Loss: 2.2518163843956044e-07\n",
      "Loss: 2.1992770904101494e-07\n",
      "Loss: 2.1479126237625413e-07\n",
      "Loss: 2.0976980544906877e-07\n",
      "Loss: 2.048609258615405e-07\n",
      "Loss: 2.0006227973884608e-07\n",
      "Loss: 1.9537160439988084e-07\n",
      "Loss: 1.9078671259412954e-07\n",
      "Loss: 1.863055172612936e-07\n",
      "Loss: 1.8192603862613993e-07\n",
      "Loss: 1.776464514822498e-07\n",
      "Loss: 1.7346512158371943e-07\n",
      "Loss: 1.6938070350398758e-07\n",
      "Loss: 1.6539225105914822e-07\n",
      "Loss: 1.614994405761256e-07\n",
      "Loss: 1.5770287768843558e-07\n",
      "Loss: 1.5400464962052263e-07\n",
      "Loss: 1.5040917099387436e-07\n",
      "Loss: 1.469246383963681e-07\n",
      "Loss: 1.4356540698706988e-07\n",
      "Loss: 1.40356022220102e-07\n",
      "Loss: 1.3733810173337336e-07\n",
      "Loss: 1.345820187760146e-07\n",
      "Loss: 1.3220754099065388e-07\n",
      "Loss: 1.304190919076018e-07\n",
      "Loss: 1.295700068619997e-07\n",
      "Loss: 1.302730786507466e-07\n",
      "Loss: 1.3360850136418606e-07\n",
      "Loss: 1.4148301977763073e-07\n",
      "Loss: 1.573300710626221e-07\n",
      "Loss: 1.873155228451293e-07\n",
      "Loss: 2.427926529160354e-07\n",
      "Loss: 3.444657144653383e-07\n",
      "Loss: 5.313627278506189e-07\n",
      "Loss: 8.754871332581889e-07\n",
      "Loss: 1.5159866557495724e-06\n",
      "Loss: 2.710512545693971e-06\n",
      "Loss: 4.969788098410793e-06\n",
      "Loss: 9.224545211044433e-06\n",
      "Loss: 1.735474635757478e-05\n",
      "Loss: 3.2539356715006866e-05\n",
      "Loss: 6.105619503809548e-05\n",
      "Loss: 0.0001105573025396563\n",
      "Loss: 0.00019253772355886723\n",
      "Loss: 0.00029503018791862505\n",
      "Loss: 0.0003836736939693943\n",
      "Loss: 0.000348825420200498\n",
      "Loss: 0.00018890878161721214\n",
      "Loss: 2.58686164027346e-05\n",
      "Loss: 1.9068591601924493e-05\n",
      "Loss: 0.00013052764397244955\n",
      "Loss: 0.00018851044080174796\n",
      "Loss: 0.00011589017521171061\n",
      "Loss: 1.3307622721224675e-05\n",
      "Loss: 1.8580185211238366e-05\n",
      "Loss: 9.30580028453246e-05\n",
      "Loss: 0.00010448706335871791\n",
      "Loss: 3.901329785391265e-05\n",
      "Loss: 1.2294384822709242e-07\n",
      "Loss: 3.559832695057524e-05\n",
      "Loss: 7.027442838125919e-05\n",
      "Loss: 4.3036910134223174e-05\n",
      "Loss: 3.327518268489408e-06\n",
      "Loss: 1.1207098392984401e-05\n",
      "Loss: 4.053637487517059e-05\n",
      "Loss: 3.657908748175568e-05\n",
      "Loss: 7.8244943633369e-06\n",
      "Loss: 2.32290570892935e-06\n",
      "Loss: 2.1548630720576137e-05\n",
      "Loss: 2.691972154202264e-05\n",
      "Loss: 1.007330647356942e-05\n",
      "Loss: 9.696872786265962e-08\n",
      "Loss: 9.938348471271636e-06\n",
      "Loss: 1.8285974582539848e-05\n",
      "Loss: 1.0278181505042452e-05\n",
      "Loss: 5.24315784672465e-07\n",
      "Loss: 3.6740750285369657e-06\n",
      "Loss: 1.1078664555386208e-05\n",
      "Loss: 9.128932520602959e-06\n",
      "Loss: 1.7058299351898416e-06\n",
      "Loss: 8.185495142233834e-07\n",
      "Loss: 5.8761410892117335e-06\n",
      "Loss: 7.089973912055693e-06\n",
      "Loss: 2.693219709802266e-06\n",
      "Loss: 4.524574563122389e-08\n",
      "Loss: 2.4533062827541156e-06\n",
      "Loss: 4.797032994262495e-06\n",
      "Loss: 3.0617812763701876e-06\n",
      "Loss: 3.35584551217994e-07\n",
      "Loss: 6.420677002463247e-07\n",
      "Loss: 2.6518379662074486e-06\n",
      "Loss: 2.7486621190818085e-06\n",
      "Loss: 9.077921557338275e-07\n",
      "Loss: 4.8922988429923984e-08\n",
      "Loss: 1.0756041919499612e-06\n",
      "Loss: 1.937723945091642e-06\n",
      "Loss: 1.246682402138201e-06\n",
      "Loss: 1.693015128273754e-07\n",
      "Loss: 2.2876060894462893e-07\n",
      "Loss: 1.0131925406952014e-06\n",
      "Loss: 1.1537408763826487e-06\n",
      "Loss: 4.833112388399438e-07\n",
      "Loss: 2.900374951823882e-08\n",
      "Loss: 3.219158446412196e-07\n",
      "Loss: 7.436983554134365e-07\n",
      "Loss: 6.206075525737072e-07\n",
      "Loss: 1.7554930759477805e-07\n",
      "Loss: 3.6994141774755284e-08\n",
      "Loss: 2.949789470765163e-07\n",
      "Loss: 4.844680454736323e-07\n",
      "Loss: 3.26819088495464e-07\n",
      "Loss: 6.990304349720273e-08\n",
      "Loss: 4.851543279436877e-08\n",
      "Loss: 2.2154189184943179e-07\n",
      "Loss: 3.013241701869995e-07\n",
      "Loss: 1.8050810461499986e-07\n",
      "Loss: 3.6661138350156774e-08\n",
      "Loss: 4.3891775850600575e-08\n",
      "Loss: 1.4953277246956752e-07\n",
      "Loss: 1.869372996110976e-07\n",
      "Loss: 1.0964482948379158e-07\n",
      "Loss: 2.605229837159391e-08\n",
      "Loss: 3.206016404828331e-08\n",
      "Loss: 9.448139168426773e-08\n",
      "Loss: 1.17946767353919e-07\n",
      "Loss: 7.4057370860728e-08\n",
      "Loss: 2.2498200400634254e-08\n",
      "Loss: 2.0991736315878007e-08\n",
      "Loss: 5.661694424280593e-08\n",
      "Loss: 7.541062247760991e-08\n",
      "Loss: 5.42070678226419e-08\n",
      "Loss: 2.1538571704141117e-08\n",
      "Loss: 1.3913158649933884e-08\n",
      "Loss: 3.218110393009551e-08\n",
      "Loss: 4.777424438079311e-08\n",
      "Loss: 4.100585150217211e-08\n",
      "Loss: 2.1393413476630152e-08\n",
      "Loss: 1.1043097425136889e-08\n",
      "Loss: 1.7670175081160617e-08\n",
      "Loss: 2.905969971036397e-08\n",
      "Loss: 3.0384941022990785e-08\n",
      "Loss: 2.070511112447335e-08\n",
      "Loss: 1.1095900204590533e-08\n",
      "Loss: 1.0477413444308832e-08\n",
      "Loss: 1.6688391811504834e-08\n",
      "Loss: 2.0998762331489132e-08\n",
      "Loss: 1.8442123594239736e-08\n",
      "Loss: 1.2091193466372432e-08\n",
      "Loss: 8.300203963996728e-09\n",
      "Loss: 9.658808241594973e-09\n",
      "Loss: 1.3199635418335021e-08\n",
      "Loss: 1.4455070199364967e-08\n",
      "Loss: 1.210314806609346e-08\n",
      "Loss: 8.588391980775199e-09\n",
      "Loss: 7.005640549924657e-09\n",
      "Loss: 8.045814583311176e-09\n",
      "Loss: 9.84739456454425e-09\n",
      "Loss: 1.0244131433522192e-08\n",
      "Loss: 8.807400781018674e-09\n",
      "Loss: 6.86789122563508e-09\n",
      "Loss: 5.957648784207371e-09\n",
      "Loss: 6.410224968805674e-09\n",
      "Loss: 7.3187307828336286e-09\n",
      "Loss: 7.57948221098051e-09\n",
      "Loss: 6.875793691135431e-09\n",
      "Loss: 5.779884923966593e-09\n",
      "Loss: 5.08598103866008e-09\n",
      "Loss: 5.107195785417396e-09\n",
      "Loss: 5.520842160845015e-09\n",
      "Loss: 5.762404746642645e-09\n",
      "Loss: 5.52578134087469e-09\n",
      "Loss: 4.948312153615042e-09\n",
      "Loss: 4.409650906997693e-09\n",
      "Loss: 4.188589246134315e-09\n",
      "Loss: 4.273432830858479e-09\n",
      "Loss: 4.432473266060519e-09\n",
      "Loss: 4.431393881296982e-09\n",
      "Loss: 4.2038038728513685e-09\n",
      "Loss: 3.8623194750817674e-09\n",
      "Loss: 3.580315989939465e-09\n",
      "Loss: 3.45783077192161e-09\n",
      "Loss: 3.4686350045430767e-09\n",
      "Loss: 3.505173738224784e-09\n",
      "Loss: 3.4676970442474616e-09\n",
      "Loss: 3.3278544221720585e-09\n",
      "Loss: 3.131234558451589e-09\n",
      "Loss: 2.952119320977334e-09\n",
      "Loss: 2.8405994506844003e-09\n",
      "Loss: 2.7969970667063415e-09\n",
      "Loss: 2.78256171443164e-09\n",
      "Loss: 2.751080945108022e-09\n",
      "Loss: 2.6774813596584567e-09\n",
      "Loss: 2.5674415640944012e-09\n",
      "Loss: 2.4472699928128568e-09\n",
      "Loss: 2.3446412436045008e-09\n",
      "Loss: 2.27319642535878e-09\n",
      "Loss: 2.228380190275245e-09\n",
      "Loss: 2.1938966396368474e-09\n",
      "Loss: 2.1526916270686323e-09\n",
      "Loss: 2.0956546935273156e-09\n",
      "Loss: 2.0242524207531425e-09\n",
      "Loss: 1.947352394447556e-09\n",
      "Loss: 1.8753048082913592e-09\n",
      "Loss: 1.8147923931446681e-09\n",
      "Loss: 1.766644663518863e-09\n",
      "Loss: 1.726817170290881e-09\n",
      "Loss: 1.6892558610886505e-09\n",
      "Loss: 1.6488948322886186e-09\n",
      "Loss: 1.6034773221033408e-09\n",
      "Loss: 1.5537685618144336e-09\n",
      "Loss: 1.5025127995157293e-09\n",
      "Loss: 1.4528993210800645e-09\n",
      "Loss: 1.4072622753759646e-09\n",
      "Loss: 1.3664397863329036e-09\n",
      "Loss: 1.3298383393283325e-09\n",
      "Loss: 1.295977606894743e-09\n",
      "Loss: 1.2631871957840908e-09\n",
      "Loss: 1.23017530201762e-09\n",
      "Loss: 1.1963203221227078e-09\n",
      "Loss: 1.1616743146586158e-09\n",
      "Loss: 1.1267648884147652e-09\n",
      "Loss: 1.092315658405776e-09\n",
      "Loss: 1.058993128053874e-09\n",
      "Loss: 1.0272428832275172e-09\n",
      "Loss: 9.972324712581739e-10\n",
      "Loss: 9.688819370955216e-10\n",
      "Loss: 9.419457992709682e-10\n",
      "Loss: 9.161090565454138e-10\n",
      "Loss: 8.910692497917226e-10\n",
      "Loss: 8.66589934290548e-10\n",
      "Loss: 8.425231492437154e-10\n",
      "Loss: 8.188066473652801e-10\n",
      "Loss: 7.954452568318983e-10\n",
      "Loss: 7.724859725663718e-10\n",
      "Loss: 7.499938751245033e-10\n",
      "Loss: 7.28033393984955e-10\n",
      "Loss: 7.066563100136494e-10\n",
      "Loss: 6.858962574775839e-10\n",
      "Loss: 6.657681434139152e-10\n",
      "Loss: 6.462707221455316e-10\n",
      "Loss: 6.273906550562718e-10\n",
      "Loss: 6.091068018020209e-10\n",
      "Loss: 5.91394007291028e-10\n",
      "Loss: 5.742259888276343e-10\n",
      "Loss: 5.575773039790954e-10\n",
      "Loss: 5.414244833599044e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[2.99998543],\n",
       "        [4.00002979],\n",
       "        [4.99997815]]),\n",
       " None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    y, l = nn(x, y_hat)\n",
    "    dx = nn.backward()\n",
    "    print(f\"Loss: {l}\")\n",
    "    lin_adam.step()\n",
    "nn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67f263d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, min_max_value, nb_data=1000, eval_ratio=0.1, batch_size=32):\n",
    "        self.min_max_value = min_max_value\n",
    "        self.nb_data = nb_data\n",
    "        self.eval_ratio = eval_ratio\n",
    "        self.batch_size = batch_size\n",
    "        x_ = np.random.uniform(-min_max_value, min_max_value, size=(nb_data, batch_size, 1))\n",
    "        y_ = np.sin(x_)\n",
    "        self.nb_eval = int(nb_data * eval_ratio)\n",
    "        self.x_train = x_[:-self.nb_eval, :, :]\n",
    "        self.y_train = y_[:-self.nb_eval, :, :]\n",
    "        self.x_eval = x_[-self.nb_eval:, :, :]\n",
    "        self.y_eval = y_[-self.nb_eval:, :, :]\n",
    "\n",
    "    def get_train_data(self):\n",
    "        return self.x_train, self.y_train\n",
    "    \n",
    "    def get_eval_data(self):\n",
    "        return self.x_eval, self.y_eval\n",
    "    \n",
    "    def eval_len(self):\n",
    "        return self.x_eval.shape[0]\n",
    "    \n",
    "    def train_len(self):\n",
    "        return self.x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "047c9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_Scheduler:\n",
    "    def __init__(self, optimizer, start_value=0.1, end_value=0.01, nb_steps=1000):\n",
    "        self.optimizer = optimizer\n",
    "        self.start_value = start_value\n",
    "        self.end_value = end_value\n",
    "        self.nb_steps = nb_steps\n",
    "        self.current_step = 0\n",
    "\n",
    "    def step(self):\n",
    "        if self.current_step < self.nb_steps:\n",
    "            lr = self.start_value + (self.end_value - self.start_value) * (self.current_step / self.nb_steps)\n",
    "            self.optimizer.lr = lr\n",
    "            self.current_step += 1\n",
    "        else:\n",
    "            self.optimizer.lr = self.end_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aeed3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(nb_layers=1, in_features=1, out_features=1, hidden_features=16, activation=Arctan())\n",
    "adam = Adam(model.get_parameters(), lr=0.01)\n",
    "nb_data = int(5*1e4)\n",
    "scheduler = LR_Scheduler(adam, start_value=0.01, end_value=1e-6, nb_steps=nb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c47ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_value = 10 \n",
    "batch_size = 128\n",
    "\n",
    "dataset = Dataset(min_max_value, nb_data=nb_data, eval_ratio=0.1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd1b9762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005089284566288509\n",
      "Evaluation: 0.48035844058888405\n",
      "0.00047948779659560525\n",
      "0.0004330356455805723\n",
      "0.00045061121482966904\n",
      "0.00047640511549120764\n",
      "0.0004569160435870435\n",
      "Evaluation: 0.46294056376689413\n",
      "2.0694480458391803e-05\n",
      "1.2752399754787114e-06\n",
      "2.638213697850939e-07\n",
      "1.5438116621190362e-06\n",
      "3.4467008290691146e-07\n",
      "Evaluation: 0.0003771206912075608\n",
      "4.321888509653993e-07\n",
      "3.4216883334606537e-07\n",
      "2.710863967270161e-07\n",
      "1.890747278396363e-07\n",
      "6.064861773673315e-07\n",
      "Evaluation: 0.0007784908498050281\n",
      "7.467887366734229e-07\n",
      "6.007643072489561e-07\n",
      "2.862634858227572e-07\n",
      "7.674163303754268e-07\n",
      "6.654970477196992e-07\n",
      "Evaluation: 0.0017514791574884225\n",
      "1.0288152304456674e-06\n",
      "6.315527688278754e-07\n",
      "8.619682551710777e-07\n",
      "6.831964245538901e-07\n",
      "4.262305969947853e-07\n",
      "Evaluation: 0.0007543732623822495\n",
      "3.663209520997587e-07\n",
      "4.193669651723547e-07\n",
      "1.1354266157166183e-06\n",
      "4.135930893872579e-07\n",
      "5.217329475282366e-07\n",
      "Evaluation: 0.0005167607095506649\n",
      "2.925486837129409e-07\n",
      "3.66109318168464e-07\n",
      "7.972206560870707e-07\n",
      "2.3662632889006184e-07\n",
      "1.7973618188315828e-07\n",
      "Evaluation: 0.00013346512677331587\n",
      "2.2901941930351094e-07\n",
      "9.6559372695644e-08\n",
      "1.232607752963979e-07\n",
      "1.6052946966086877e-07\n",
      "1.5785000118524127e-07\n",
      "Evaluation: 0.00019939368959214797\n",
      "2.4354783275383895e-07\n",
      "9.594040563828326e-08\n",
      "7.099686499964843e-08\n",
      "7.840615838887264e-08\n"
     ]
    }
   ],
   "source": [
    "logging_loss = 0\n",
    "eval_step = 5000\n",
    "logging_step = 1000\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    return x / min_max_value\n",
    "\n",
    "def evaluate(model,):\n",
    "    eval_log_loss = 0\n",
    "    for x, y in zip(*dataset.get_eval_data()):\n",
    "        x = normalize(x)\n",
    "        loss = model(x, y)[1]\n",
    "        eval_log_loss += loss\n",
    "    print(f\"Evaluation: {eval_log_loss.item()/ dataset.eval_len()}\")\n",
    "    \n",
    "\n",
    "for idx, (x, y) in enumerate(zip(*dataset.get_train_data())):\n",
    "    x = normalize(x)\n",
    "    loss = model(x, y)[1]\n",
    "    model.backward()\n",
    "    adam.step()\n",
    "    scheduler.step()\n",
    "    logging_loss = loss.item()\n",
    "    if idx % logging_step == 0:\n",
    "        print(logging_loss/logging_step)\n",
    "        logging_loss = 0\n",
    "    if idx % eval_step == 0:\n",
    "        evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c96ccc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10, 10, 1000)\n",
    "x = x.reshape(-1, 1)\n",
    "x_ = normalize(x)\n",
    "y_model = model(x_)[0]\n",
    "plt.plot(x, y_model, label=\"model\")\n",
    "plt.plot(x, np.sin(x), '.', label=\"sinus\", markersize=0.5)\n",
    "plt.xlim(-10,10)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc8d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
